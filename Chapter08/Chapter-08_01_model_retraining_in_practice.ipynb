{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOoIE6oiw55u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwWbC_7A1X56",
        "outputId": "9bf9526b-35e3-4fdf-a141-ff2623f545d5"
      },
      "outputs": [],
      "source": [
        "len(pd.read_csv('/content/heart.csv'))\n",
        "df = (pd.read_csv('/content/heart.csv'))\n",
        "df = df[['Age', 'RestingBP', 'Cholesterol', 'FastingBS',\n",
        "       'MaxHR',  'Oldpeak', 'HeartDisease']]\n",
        "df['HeartDisease'] = df['HeartDisease'].astype('str')\n",
        "df.rename(columns = {'HeartDisease': 'label'}, inplace = True)\n",
        "df1 = df[:450]\n",
        "df2 = df[451:900]\n",
        "df1.to_csv('new_data.csv')\n",
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6rJyWyR3RxJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "features = df2.drop('label', axis=1)\n",
        "target = df2['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=0)\n",
        "data_old =X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UE2YTcyCGW0"
      },
      "source": [
        "# Assessing the need for retraining\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqhJABkI1ef4",
        "outputId": "50ec3c01-92dc-4b6c-d3b7-223c7aae9c33"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def monitor_model_performance(model, X_test, y_test):\n",
        "  predictions = model.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, predictions)\n",
        "  return accuracy # Assuming threshold_accuracy is the minimum acceptable accuracy\n",
        "threshold_accuracy = 0.85\n",
        "  # Example: Using a RandomForest Classifier as a pre-trained model\n",
        "  # Load your pre-trained model (this is just a placeholder for your actual model)\n",
        "pretrained_model = RandomForestClassifier()\n",
        "pretrained_model.fit(X_train, y_train)\n",
        "\n",
        "current_accuracy = monitor_model_performance(pretrained_model, X_test, y_test)\n",
        "print(f\"Pre trained Model Accuracy: {current_accuracy}\")\n",
        "if current_accuracy < threshold_accuracy:\n",
        "  print(\"Model drift detected. Accuracy has fallen below the threshold.\")\n",
        "else:\n",
        "  print(\"Model is performing within acceptable limits.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcyaN4JJ5WR1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Example: Loading new data for retraining\n",
        "new_dataset = pd.read_csv('new_data.csv', index_col=0)\n",
        "new_dataset['label'] = new_dataset['label'].astype('str')\n",
        "# Preprocessing steps\n",
        "# Assume 'label' as the target variable\n",
        "features = new_dataset.drop('label', axis=1)\n",
        "target = new_dataset['label']\n",
        "# Split the data into training and test sets\n",
        "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(features, target, test_size=0.2, random_state=0)\n",
        "X_train_new, X_val_new, y_train_new, y_val_new = train_test_split(X_train_new, y_train_new, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEfb4Sm0DqH_"
      },
      "outputs": [],
      "source": [
        "X_train_sample = X_train_new\n",
        "y_train_sample = y_train_new\n",
        "X_val_sample = X_val_new\n",
        "y_val_sample = y_val_new\n",
        "X_initial = X_train\n",
        "y_initial = y_train\n",
        "X_new = X_train_new\n",
        "y_new = y_train_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCZQE7DM1sgU",
        "outputId": "3d129750-51ed-403b-e973-86c3935c4174"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ks_2samp\n",
        "def detect_drift(model, data_old, data_new):\n",
        "  \"\"\" Detects model drift by comparing model predictions on two different datasets.\n",
        "  :param model: Trained classification model.\n",
        "  :param data_old: Older dataset (numpy array).\n",
        "  :param data_new: Newer dataset (numpy array).\n",
        "  :return: KS statistic and p-value. \"\"\"\n",
        "  # Generate predictions for both datasets\n",
        "  preds_old = model.predict_proba(data_old)[:,1]\n",
        "  # Assuming binary classification\n",
        "  preds_new = model.predict_proba(data_new)[:, 1]\n",
        "  # Perform Kolmogorov-Smirnov test\n",
        "  ks_stat, p_value = ks_2samp(preds_old, preds_new)\n",
        "  return ks_stat, p_value\n",
        "# Using above function to detect model drift\n",
        "initial_data = (X_initial) # Your initial dataset\n",
        "new_data = (X_new) # Your new dataset\n",
        "ks_stat, p_value = detect_drift(pretrained_model, initial_data, new_data)\n",
        "print(f\"KS Statistic: {ks_stat}, P-value: {p_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lYIa2IFCaOW"
      },
      "source": [
        "# Retraining the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qf5Q6LtDSko",
        "outputId": "b052b8a4-d37e-4f05-ac1f-6c50efb827b2"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Example algorithms\n",
        "model_rf = RandomForestClassifier()\n",
        "model_gb = GradientBoostingClassifier()\n",
        "# Fit models on a sample of the new data\n",
        "model_rf.fit(X_train_sample, y_train_sample)\n",
        "model_gb.fit(X_train_sample, y_train_sample)\n",
        "# Evaluate and compare\n",
        "accuracy_rf = accuracy_score(y_val_sample, model_rf.predict(X_val_sample))\n",
        "accuracy_gb = accuracy_score(y_val_sample, model_gb.predict(X_val_sample))\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf}, Gradient Boosting Accuracy: {accuracy_gb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1cR1Tf1Z2td",
        "outputId": "084693e5-3e09-457d-fdc3-974cc92e2287"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Set up hyperparameter grid\n",
        "param_grid = { 'n_estimators': [100, 200], 'max_depth': [10, 20, 30] }\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=model_rf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
        "# Perform grid search on the training data\n",
        "grid_search.fit(X_train_new, y_train_new)\n",
        "# Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3siYpdlfiqRO",
        "outputId": "666317a8-62d2-4ecf-ee8f-a569f2f19cd1"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "# Train the model with optimal parameters\n",
        "optimal_model = RandomForestClassifier(n_estimators=200, max_depth=30)\n",
        "optimal_model.fit(X_train_new, y_train_new)\n",
        "# Save the retrained model\n",
        "joblib.dump(optimal_model, \"retrained_model.joblib\")\n",
        "# Evaluate the retrained model\n",
        "retrained_predictions = optimal_model.predict(X_test_new)\n",
        "print(f\"Retrained Model Accuracy: {accuracy_score(y_test_new, retrained_predictions)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgL33ORFC4LD"
      },
      "source": [
        "# Active model selection and deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTaJ_cXane7i",
        "outputId": "5f25878e-b610-48ed-e0c2-acc94e3dc5db"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Assuming you have a retrained model and a baseline model\n",
        "retrained_model_accuracy = accuracy_score(y_test_new, optimal_model.predict(X_test_new))\n",
        "baseline_model_accuracy = accuracy_score(y_test_new, pretrained_model.predict(X_test_new))\n",
        "\n",
        "# Define performance threshold\n",
        "performance_threshold = baseline_model_accuracy * 1.05  # 5% improvement\n",
        "# Check if the retrained model meets the threshold\n",
        "if retrained_model_accuracy >= performance_threshold:\n",
        "  print(\"Retrained model meets the performance threshold.\")\n",
        "else:\n",
        "  print(\"Retrained model does not meet the performance threshold.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfvztbGuiayn"
      },
      "outputs": [],
      "source": [
        "users = pd.DataFrame({\n",
        "    'id': [1,2,3,4,5],\n",
        "    'role':['user','user','user','user','user'],\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFlk17NYvSFK"
      },
      "outputs": [],
      "source": [
        "def assign_model(user_id):\n",
        "  return 'retrained_model' if np.random.rand() < 0.5 else 'baseline_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nw5t0U2XiKQr"
      },
      "outputs": [],
      "source": [
        "for index, row in users.iterrows():\n",
        "  model_assigned = assign_model(row.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfkzXYl8i0l8",
        "outputId": "c737614f-87bc-4c49-f177-db53489c6447"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def old_model_predict(input_data):\n",
        "    # Placeholder for the old model's prediction logic\n",
        "    return \"old_model_prediction\"\n",
        "\n",
        "def new_model_predict(input_data):\n",
        "    # Placeholder for the new model's prediction logic\n",
        "    return \"new_model_prediction\"\n",
        "\n",
        "def gradual_rollout(input_data, rollout_percentage):\n",
        "    \"\"\"\n",
        "    Gradually rollout the new model based on the specified percentage.\n",
        "    :param input_data: The input data for prediction.\n",
        "    :param rollout_percentage: Percentage of traffic to direct to the new model.\n",
        "    :return: The model's prediction.\n",
        "    \"\"\"\n",
        "    if random.random() < rollout_percentage:\n",
        "        return new_model_predict(input_data)\n",
        "    else:\n",
        "        return old_model_predict(input_data)\n",
        "\n",
        "# Example usage\n",
        "rollout_percentage = 0.10  # Start with 10% of the traffic to the new model\n",
        "input_data = np.random.rand(20)  # Example input data\n",
        "\n",
        "# Simulating requests\n",
        "for _ in range(100):\n",
        "    prediction = gradual_rollout(input_data, rollout_percentage)\n",
        "    print(prediction)\n",
        "\n",
        "    # Based on monitoring, gradually increase the rollout_percentage\n",
        "    # This increment can be based on time or performance metrics\n",
        "    # e.g., rollout_percentage += 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrUWPBjrGBma"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
