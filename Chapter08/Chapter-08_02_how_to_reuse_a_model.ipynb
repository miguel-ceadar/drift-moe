{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nin4Q6RHwp5G"
      },
      "source": [
        "# Utilizing Model pools in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mWNxIdzrj5-",
        "outputId": "a51cf7a7-d9be-4bcc-d489-bbd41b17b7f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:08<00:00, 21244345.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sebasmos/anaconda3/envs/book/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/sebasmos/anaconda3/envs/book/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/sebasmos/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 104MB/s] \n",
            "/Users/sebasmos/anaconda3/envs/book/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/sebasmos/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 101MB/s]  \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Define your dataset here\n",
        "# For the sake of example, let's assume we are using CIFAR10\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_dataset_1 = Subset(train_dataset,range(1, len(train_dataset), 10))\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_dataset_1 = Subset(test_dataset,range(1, len(test_dataset), 10))\n",
        "\n",
        "train_loader = DataLoader(train_dataset_1, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset_1, batch_size=100, shuffle=False)\n",
        "\n",
        "# Define the model pool\n",
        "model_pool = {\n",
        "    'resnet18': models.resnet18(pretrained=True),\n",
        "    'vgg16': models.vgg16(pretrained=True)\n",
        "}\n",
        "\n",
        "# Modify the final layer of each model to fit the CIFAR10 dataset\n",
        "num_classes = 10\n",
        "model_pool['resnet18'].fc = nn.Linear(model_pool['resnet18'].fc.in_features, num_classes)\n",
        "model_pool['vgg16'].classifier[6] = nn.Linear(model_pool['vgg16'].classifier[6].in_features, num_classes)\n",
        "\n",
        "# Function to train and evaluate a model\n",
        "def train_and_evaluate(model, train_loader, test_loader, epochs=1):\n",
        "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            #data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            #data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = correct / len(test_loader.dataset)\n",
        "    return test_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wukhzjBstVIt",
        "outputId": "0c24a8e8-b895-4623-f5a9-5a81ce681ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and evaluating resnet18\n",
            "Model: resnet18, Accuracy: 0.548\n",
            "Training and evaluating vgg16\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate each model in the pool\n",
        "model_performance = {}\n",
        "for model_name, model in model_pool.items():\n",
        "    print(f\"Training and evaluating {model_name}\")\n",
        "    accuracy = train_and_evaluate(model, train_loader, test_loader)\n",
        "    model_performance[model_name] = accuracy\n",
        "    print(f\"Model: {model_name}, Accuracy: {accuracy}\")\n",
        "\n",
        "# Find the best performing model\n",
        "best_model_name = max(model_performance, key=model_performance.get)\n",
        "print(f\"Best model: {best_model_name} with accuracy: {model_performance[best_model_name]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY7jQKbdGaxI"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgiW5R1IGmXj",
        "outputId": "04363402-1b4a-4227-fbda-99725682165d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 122MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "# Load a pre-trained model\n",
        "model = models.resnet50(pretrained=True)\n",
        "# Freeze all layers in the model\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# Replace the final layer with a new one for our specific task\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, num_classes)\n",
        "# num_classes is the number of your new classes\n",
        "# Fine-tuning the model\n",
        "# Assume the use of a dataloader 'train_loader'\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs): # num_epochs is your desired number of epochs\n",
        "  for inputs, labels in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeJh4C8_LA81"
      },
      "source": [
        "# Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6A-DxBMKcue",
        "outputId": "e69234cf-f2f6-428d-8594-58ddeb7da969"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Load a pre-trained model and set it to evaluation mode\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.eval()\n",
        "# Define a transformation for the input data\n",
        "transform = transforms.Compose([ transforms.Resize(256),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                 transforms.ToTensor() ])\n",
        "\n",
        "# Load your dataset\n",
        "# Assume the use of a dataloader 'test_loader'\n",
        "# Extract features\n",
        "features = []\n",
        "with torch.no_grad():\n",
        "  for inputs, _ in test_loader:\n",
        "    outputs = model(inputs)\n",
        "    features.extend(outputs)\n",
        "\n",
        "# 'features' now contains the extracted features from the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUMIHBVP85hD"
      },
      "source": [
        "# Ensemble Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM5Cj0Js84jH",
        "outputId": "13312a1d-fab6-4083-bbe4-05e8839713bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Model Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Load a sample dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize pre-trained models (these should be replaced with your actual pre-trained models)\n",
        "model1 = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
        "model2 = GradientBoostingClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
        "model3 = LogisticRegression(max_iter=200, random_state=42).fit(X_train, y_train)\n",
        "\n",
        "# Creating an ensemble using Voting Classifier\n",
        "ensemble_model = VotingClassifier(estimators=[ ('model1', model1),\n",
        " ('model2', model2),\n",
        "  ('model3', model3) ], voting='hard')\n",
        "# Fit ensemble model on training data and evaluate\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "ensemble_predictions = ensemble_model.predict(X_test)\n",
        "print(f\"Ensemble Model Accuracy: {accuracy_score(y_test, ensemble_predictions)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yaYPsfyQaS1"
      },
      "source": [
        "# Cross Domain Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bEL1WR2SRAB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "retail_df = pd.read_csv('/content/retail_sales_dataset.csv')\n",
        "retail_df = retail_df.drop(['Gender','Date', 'Customer ID', 'Transaction ID'], axis=1)\n",
        "retail_df['Product Category'] = pd.Categorical(retail_df['Product Category'])\n",
        "retail_df['Product Category Codes'] = retail_df['Product Category'].cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUN8RlbPVSfX"
      },
      "outputs": [],
      "source": [
        "features = retail_df.drop(['Total Amount','Product Category'] , axis=1)\n",
        "scaler = StandardScaler()\n",
        "retail_features_scaled = scaler.fit_transform(features)\n",
        "target = retail_df['Total Amount']\n",
        "X_train, X_test, y_train, y_test = train_test_split(retail_features_scaled, target, test_size=0.3, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgPY8pyNWXYL"
      },
      "outputs": [],
      "source": [
        "#Function for creating and predicting values\n",
        "def model_predict(model_name,X_train,y_train):\n",
        "  regressor = model_name\n",
        "\n",
        "  # Fit the Algorithm\n",
        "  regressor.fit(X_train, y_train)\n",
        "\n",
        "  # Predicting on the test set\n",
        "  y_pred_test = regressor.predict(X_test)\n",
        "\n",
        "  return y_pred_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPJ2FUC1WcK8",
        "outputId": "6b797d29-402d-44d6-8776-62ff81976747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error in Reatil Sales: 44620.781249803535\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['retail_model.joblib']"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Creating instance of model\n",
        "retail_model=LinearRegression()\n",
        "\n",
        "#Predicting on test set\n",
        "y_pred_test_lr=model_predict(model_name=retail_model,X_train=X_train,y_train=y_train)\n",
        "\n",
        "retail_mse = mean_squared_error(y_test, y_pred_test_lr)\n",
        "\n",
        "print(f\"Mean Squared Error in Reatil Sales: {retail_mse}\")\n",
        "\n",
        "joblib.dump(retail_model, \"retail_model.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAPPjIG6Vjdp"
      },
      "outputs": [],
      "source": [
        "online_df = pd.read_csv('/content/OnlineCustomerSalesData.csv')\n",
        "online_df = online_df.drop(['Customer_id', 'Gender','Purchase_DATE', 'Purchase_VALUE','Browser', 'Newsletter', 'Voucher'] , axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GzZt6wnbaIOf",
        "outputId": "1bb3b684-c776-4005-df03-a13a972c759a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3f686b62-7fe3-479c-8b75-748fcd257190\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Revenue_Total</th>\n",
              "      <th>N_Purchases</th>\n",
              "      <th>Pay_Method</th>\n",
              "      <th>Time_Spent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>53</td>\n",
              "      <td>45.3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>36.2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>52</td>\n",
              "      <td>10.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>29</td>\n",
              "      <td>54.1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>56.9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65791</th>\n",
              "      <td>30</td>\n",
              "      <td>10.9</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65792</th>\n",
              "      <td>33</td>\n",
              "      <td>29.3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65793</th>\n",
              "      <td>50</td>\n",
              "      <td>25.4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65794</th>\n",
              "      <td>56</td>\n",
              "      <td>29.2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65795</th>\n",
              "      <td>25</td>\n",
              "      <td>5.3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>820</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65796 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f686b62-7fe3-479c-8b75-748fcd257190')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f686b62-7fe3-479c-8b75-748fcd257190 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f686b62-7fe3-479c-8b75-748fcd257190');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b1ff71f-bc3b-47c8-9b49-4b338b5805cd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b1ff71f-bc3b-47c8-9b49-4b338b5805cd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b1ff71f-bc3b-47c8-9b49-4b338b5805cd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       Age  Revenue_Total  N_Purchases  Pay_Method  Time_Spent\n",
              "0       53           45.3            2           1         885\n",
              "1       18           36.2            3           2         656\n",
              "2       52           10.6            1           0         761\n",
              "3       29           54.1            5           1         906\n",
              "4       21           56.9            1           1         605\n",
              "...    ...            ...          ...         ...         ...\n",
              "65791   30           10.9            4           1         894\n",
              "65792   33           29.3            1           0         722\n",
              "65793   50           25.4            5           3         424\n",
              "65794   56           29.2            1           3         731\n",
              "65795   25            5.3            2           0         820\n",
              "\n",
              "[65796 rows x 5 columns]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "online_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqXZAkD1USmd"
      },
      "outputs": [],
      "source": [
        "online_marketplace_features = online_df.drop( 'Revenue_Total', axis=1)\n",
        "online_marketplace_target = online_df['Revenue_Total']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdyeAN0POjaU",
        "outputId": "25536cc3-9aa1-4e08-8ff9-fbdd9a7c0b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error in Online Marketplace: 457470.9124484482\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['online_sales_model.joblib']"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the pre-trained retail sales model\n",
        "model = joblib.load('/content/retail_model.joblib')\n",
        "# Preprocess online marketplace data\n",
        "scaler = StandardScaler()\n",
        "online_marketplace_features_scaled = scaler.fit_transform(online_marketplace_features)\n",
        "# Apply the model to the target domain\n",
        "predicted_sales = model.predict(online_marketplace_features_scaled)\n",
        "# Calculate the model's performance\n",
        "mse = mean_squared_error(online_marketplace_target, predicted_sales)\n",
        "print(f\"Mean Squared Error in Online Marketplace: {mse}\")\n",
        "\n",
        "joblib.dump(model, \"online_sales_model.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fx7y4aOcYNL"
      },
      "source": [
        "# Resource Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcDuU9Ufbb4l",
        "outputId": "5b8b3ad6-1eb0-46bc-a6a2-0cacca7b1957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "1/1 [==============================] - 1s 887ms/step\n"
          ]
        }
      ],
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "ffrom tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "# Load a pre-trained VGG16 model\n",
        "model = VGG16(weights='imagenet', include_top=False)\n",
        "# Function to prepare an image for the model\n",
        "def prepare_image(file_path):\n",
        "  img = load_img(file_path,\n",
        "                 target_size=(224, 224))\n",
        "  img_array = img_to_array(img)\n",
        "  img_array_expanded = np.expand_dims(img_array, axis=0)\n",
        "  return preprocess_input(img_array_expanded)\n",
        "# Prepare and predict on a new image\n",
        "test_image = prepare_image('/content/dataset/HappyFish.jpg')\n",
        "features = model.predict(test_image)\n",
        "# Use features for classification or further processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUwKJpSDdEfj",
        "outputId": "dbc87e70-d517-457a-fffa-0946c16bf714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 565ms/step\n",
            "Feature extraction took 0.6298120021820068 seconds.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# Example: Timing the feature extraction\n",
        "start_time = time.time()\n",
        "features = model.predict(test_image)\n",
        "end_time = time.time()\n",
        "print(f\"Feature extraction took {end_time - start_time} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzCftEUTc8fV"
      },
      "source": [
        "# Concept Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8P6jwxegFlM",
        "outputId": "b940cbc0-dbe5-42ec-b9d4-5b389e7aa0f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Similar Models based on Feature Cosine Similarity:\n",
            "('resnet18', 'vgg16'): 0.5362259149551392\n",
            "('alexnet', 'vgg16'): 0.6577829122543335\n",
            "('vgg16', 'resnet18'): 0.5362259149551392\n",
            "('vgg16', 'alexnet'): 0.6577829122543335\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "# Load pre-trained models\n",
        "model_names = ['resnet18', 'alexnet', 'vgg16']\n",
        "models = {name: getattr(models, name)(pretrained=True) for name in model_names}\n",
        "for model in models.values():\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to fit models' input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "dataset_1 = Subset(dataset,range(1, len(dataset), 10))\n",
        "loader = DataLoader(dataset_1, batch_size=10, shuffle=True)\n",
        "\n",
        "def extract_features(model, loader):\n",
        "    with torch.no_grad():\n",
        "        for images, _ in loader:\n",
        "            return model(images).flatten(1)  # Flatten the features\n",
        "\n",
        "# Extract features from the first batch\n",
        "features = {name: extract_features(model, loader) for name, model in models.items()}\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity_threshold = 0.5\n",
        "similar_models = {}\n",
        "for name1, features1 in features.items():\n",
        "    for name2, features2 in features.items():\n",
        "        if name1 != name2:\n",
        "            similarity = cosine_similarity(features1, features2).mean().item()\n",
        "\n",
        "            if similarity > similarity_threshold:\n",
        "                similar_models[(name1, name2)] = similarity\n",
        "\n",
        "\n",
        "print(\"Similar Models based on Feature Cosine Similarity:\")\n",
        "for model_pair, sim in similar_models.items():\n",
        "    print(f\"{model_pair}: {sim}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il75lupYhSrx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
