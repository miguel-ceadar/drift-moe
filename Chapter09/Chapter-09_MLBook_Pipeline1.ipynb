{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5061fdbe-7373-4da7-93b4-8f78c20ce55d",
   "metadata": {},
   "source": [
    "# Building your first ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7229e5-4c69-4ca7-b76f-568e304e60ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from river import compose, preprocessing, linear_model\n",
    "from river.datasets import synth\n",
    "from river.utils import VectorDict\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import pickle  # For model serialization\n",
    "import os  # For handling file operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f871a117",
   "metadata": {},
   "source": [
    "To run MLflow, start the server with:\n",
    "```bash\n",
    "mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns\n",
    "```\n",
    "Ensure it matches the port you pre-configured, on this case, port 5000. You can then access the MLflow interface at [http://127.0.0.1:5000](http://127.0.0.1:5000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c1ec3b-2957-4f12-9986-c09dbc55c696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize MLFlow tracking\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')  # Adjust as necessary\n",
    "experiment_name = 'MLBook_Experiment'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Define a simple data pipeline for online learning\n",
    "model = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2fb6a56-ad3c-451b-8ab3-0048e9df0da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to serialize and log the model to MLFlow\n",
    "def log_model_to_mlflow(model, run_id):\n",
    "    # Serialize the model\n",
    "    serialized_model = pickle.dumps(model)\n",
    "\n",
    "    # Save the serialized model to a file\n",
    "    model_filename = \"online_model.pkl\"\n",
    "    with open(model_filename, \"wb\") as f:\n",
    "        f.write(serialized_model)\n",
    "\n",
    "    # Log the model file to MLFlow\n",
    "    mlflow.log_artifact(model_filename, artifact_path='model')\n",
    "\n",
    "    # Clean up the model file\n",
    "    os.remove(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dc0f1b1-1aff-4b62-9c8a-592cb29886d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _retrieve_mlflow_experiment_id(name, create=False):\n",
    "        experiment_id = None\n",
    "        if name:\n",
    "            existing_experiment = mlflow.tracking.MlflowClient().get_experiment_by_name(name)\n",
    "            if existing_experiment:\n",
    "                experiment_id = existing_experiment.experiment_id\n",
    "            else:\n",
    "                if create:\n",
    "                    experiment_id = mlflow.create_experiment(name)\n",
    "                else:\n",
    "                    raise Exception(\n",
    "                        'Experiment \"{}\" not found in {}'.format(\n",
    "                            name, mlflow.get_tracking_uri()\n",
    "                        )\n",
    "                    )\n",
    "        return experiment_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881dd94f-14cb-437d-a7ff-e59330273405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulate a data stream (in practice, this would be your real-time data source)\n",
    "data_stream = synth.Agrawal(classification_function=0, seed=42).take(1000)\n",
    "\n",
    "import mlflow\n",
    "import pickle\n",
    "\n",
    "def load_latest_model():\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
    "    run_infos = client.search_runs([experiment_id])\n",
    "\n",
    "    if run_infos:\n",
    "        # Sort the runs by start time and get the latest one\n",
    "        latest_run_info = max(run_infos, key=lambda run_info: run_info.info.start_time)\n",
    "        latest_run = client.get_run(latest_run_info.info.run_id)\n",
    "\n",
    "        try:\n",
    "            local_path = client.download_artifacts(latest_run.info.run_id, \"model/online_model.pkl\")\n",
    "            with open(local_path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download model artifact: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd744a6a-f381-439a-90c9-09e10822632c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online learning and model updating completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize an MLFlow run outside the loop\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    # Online learning loop\n",
    "    for x, y in data_stream:\n",
    "    # Convert x to a regular dict if it's a VectorDict\n",
    "        if isinstance(x, VectorDict):\n",
    "            x = dict(x)\n",
    "            \n",
    "    for i, (x, y) in enumerate(data_stream):\n",
    "       \n",
    "        # Periodically load the latest model from MLFlow, for example, every 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            latest_model = load_latest_model()\n",
    "            if latest_model:\n",
    "                model = latest_model\n",
    "\n",
    "        # Inference (test-then-train)\n",
    "        y_pred = model.predict_one(x)\n",
    "\n",
    "        # Update the model with the new data point\n",
    "        model.learn_one(x, y)\n",
    "\n",
    "        # Log the updated model to MLFlow periodically, for example, every 100 iterations\n",
    "        if i % 100 == 99:\n",
    "            log_model_to_mlflow(model, run_id)\n",
    "\n",
    "    # Log the final model state\n",
    "    log_model_to_mlflow(model, run_id)\n",
    "\n",
    "print(\"Online learning and model updating completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
