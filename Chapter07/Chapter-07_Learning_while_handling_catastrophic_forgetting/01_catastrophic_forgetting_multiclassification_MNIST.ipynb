{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catastrophic forgetting for multi-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Subset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd \n",
    "import models as models\n",
    "# Set the seed for PyTorch\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from Original Pytorch github https://github.com/pytorch/examples/blob/main/mnist/main.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_remap_target(target, class_list):\n",
    "    \"\"\"\n",
    "    Automatically remap target values to the range [0, num_classes-1].\n",
    "\n",
    "    Args:\n",
    "    - target (torch.Tensor): Target tensor with original class indices.\n",
    "    - class_list (list): List of class indices in your classification task.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Remapped target tensor.\n",
    "    \"\"\"\n",
    "    remap_dict = {class_val: idx for idx, class_val in enumerate(class_list)}\n",
    "    remapped_target = torch.tensor([remap_dict[val.item()] for val in target])\n",
    "    return remapped_target\n",
    "\n",
    "def inverse_remap_target(remapped_target, class_list):\n",
    "    \"\"\"\n",
    "    Map remapped target values back to their original values.\n",
    "\n",
    "    Args:\n",
    "    - remapped_target (torch.Tensor): Remapped target tensor.\n",
    "    - class_list (list): List of class indices in your classification task.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Original target tensor.\n",
    "    \"\"\"\n",
    "    original_target = torch.tensor([class_list[idx] for idx in remapped_target])\n",
    "    return original_target\n",
    "\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch, label_types=[0, 1, 2, 3, 4, 9]):\n",
    "    \"\"\"\n",
    "    Train the neural network model using negative log-likelihood loss for multi classification.\n",
    "\n",
    "    Args:\n",
    "    - args: Commacnd-line arguments and configurations.\n",
    "    - model: The neural network model to be trained.\n",
    "    - device: The device to which data and model should be moved (e.g., \"cuda\" for GPU or \"cpu\").\n",
    "    - train_loader: DataLoader providing training data.\n",
    "    - optimizer: Optimizer for updating model parameters.\n",
    "    - epoch: The current epoch number.\n",
    "    - label_types: unique labels per task\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Accuracy of the model on the training set.\n",
    "    - average_loss: Average binary cross-entropy loss over the training set.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        remapped_target = auto_remap_target(target, label_types)\n",
    "        \n",
    "        loss = F.nll_loss(output, remapped_target)\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        pred = inverse_remap_target(pred, label_types)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "    # Calculate and return the average loss and accuracy\n",
    "    average_loss = total_loss / len(train_loader.dataset)\n",
    "    accuracy = 100.*correct / len(train_loader.dataset)\n",
    "    return accuracy, average_loss\n",
    "\n",
    "def validate(model, device, dataloader, label_types=[0, 1, 2, 3, 4, 9]):\n",
    "    \"\"\"\n",
    "    Evaluate the neural network model on a validation or test set using binary cross-entropy loss for binary classification.\n",
    "\n",
    "    Args:\n",
    "    - model: The neural network model to be evaluated.\n",
    "    - device: The device to which data and model should be moved (e.g., \"cuda\" for GPU or \"cpu\").\n",
    "    - test_loader: DataLoader providing validation or test data.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Accuracy of the model on the validation or test set.\n",
    "    - val_loss: Binary cross-entropy loss on the validation or test set.\n",
    "    - all_predictions: Predicted labels for all instances in the validation or test set.\n",
    "    - all_labels: True labels for all instances in the validation or test set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            for data, target in dataloader:\n",
    "                \n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "        \n",
    "                remapped_target = auto_remap_target(target, label_types)\n",
    "                val_loss = F.nll_loss(output, remapped_target, reduction='sum').item()\n",
    "                pred = output.argmax(dim=1)  # get the index of the max log-probability\n",
    "                pred = inverse_remap_target(pred, label_types)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                all_predictions.append(pred.cpu().numpy())\n",
    "                all_labels.append(target.cpu().numpy())\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_predictions = np.array(all_predictions).squeeze(0)\n",
    "    all_labels = np.array(all_labels).squeeze(0)\n",
    "    \n",
    "    val_loss /= len(dataloader.dataset)\n",
    "    accuracy = 100. * correct / len(dataloader.dataset)\n",
    "    print('\\Val set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(dataloader.dataset),\n",
    "        100. * correct / len(dataloader.dataset)))\n",
    "    \n",
    "    return accuracy, val_loss, all_predictions, all_labels\n",
    "    \n",
    "def train_and_validate(args, \n",
    "                       model, \n",
    "                       device, \n",
    "                       train_loader, \n",
    "                       val_loader, \n",
    "                       optimizer, \n",
    "                       scheduler, \n",
    "                       title = \"\", \n",
    "                       type_label=[0, 1, 2, 3, 4, 9],\n",
    "                       model_path= \"model.pt\"):\n",
    "    \"\"\"\n",
    "    Train and validate a neural network model across multiple epochs.\n",
    "\n",
    "    Args:\n",
    "    - args: Command-line arguments and configurations.\n",
    "    - model: The neural network model to be trained and validated.\n",
    "    - device: The device to which data and model should be moved (e.g., \"cuda\" for GPU or \"cpu\").\n",
    "    - train_loader: DataLoader providing training data.\n",
    "    - val_loader: DataLoader providing validation or test data.\n",
    "    - optimizer: Optimizer for updating model parameters.\n",
    "    - scheduler: Learning rate scheduler.\n",
    "    - title: Title for the plot (optional).\n",
    "    - model_path: path to store the model\n",
    "\n",
    "    Returns:\n",
    "    - all_predictions: Predicted labels for all instances in the validation or test set.\n",
    "    - all_labels: True labels for all instances in the validation or test set.\n",
    "    \"\"\"\n",
    "    train_losses = [] \n",
    "    train_accuracies = [] \n",
    "    val_accuracies = [] \n",
    "    val_losses = [] \n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train_accuracy, train_loss = train(args, model, device, train_loader, optimizer, epoch,type_label)\n",
    "        val_accuracy, val_loss, all_predictions, all_labels = validate(model, device, val_loader,type_label)\n",
    "        scheduler.step()\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_losses.append(train_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "        if val_loss<best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            if os.path.exists(model_path):\n",
    "                os.remove(model_path)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "\n",
    "        print(f'Epoch {epoch}/{args.epochs}: Training Loss: {train_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    print(f\"Best validation loss: {best_val_loss:.4f} at epoch {best_epoch + 1}\")\n",
    "    # Plot loss and accuracy after all epochs\n",
    "    plot_loss_and_accuracy(train_accuracies, train_losses, val_accuracies, val_losses, title)\n",
    "    \n",
    "    return all_predictions, all_labels\n",
    "\n",
    "def save_model_state_dict(model_state_dict, filename, overwrite=True):\n",
    "    \"\"\"\n",
    "    Save the state dictionary of a PyTorch model to a file.\n",
    "\n",
    "    Args:\n",
    "    - model_state_dict: The state dictionary of the PyTorch model.\n",
    "    - filename: The name of the file to which the state dictionary will be saved.\n",
    "    - overwrite: Boolean flag indicating whether to overwrite an existing file (default is True).\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    models_folder = \"models\"\n",
    "    \n",
    "    # Check if the models folder exists, if not, create it\n",
    "    if not os.path.exists(models_folder):\n",
    "        os.makedirs(models_folder)\n",
    "\n",
    "    file_path = os.path.join(models_folder, filename)\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(file_path) and not overwrite:\n",
    "        user_input = input(f\"The file '{filename}' already exists. Do you want to overwrite it? (yes/no): \")\n",
    "        if user_input.lower() != 'yes':\n",
    "            print(\"Model not saved.\")\n",
    "            return\n",
    "\n",
    "    # Save the model state dict\n",
    "    torch.save(model_state_dict, file_path)\n",
    "    print(f\"Model state dict saved to: {file_path}\")\n",
    "    \n",
    "def plot_loss_and_accuracy(train_accuracies, train_losses, val_accuracies, val_losses, title = \"\"):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Plot Training Loss and Accuracy\n",
    "    \n",
    "    ax1.plot(train_accuracies, label='Training Accuracy')\n",
    "    ax1.plot(val_accuracies, label='Validation Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_title(f'{title} - training data')\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot Testing Loss and Accuracy\n",
    "    ax2.plot(train_losses, label='Training Loss')\n",
    "    ax2.plot(val_losses, label='Validation Loss')\n",
    "    \n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_title(f'{title} - validation data')\n",
    "    ax2.legend()\n",
    "    \n",
    "def get_data_loaders(dataset, train_size, val_size, train_kwargs, val_kwargs):\n",
    "    train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_set, **train_kwargs)\n",
    "    val_loader = DataLoader(val_set, **val_kwargs)\n",
    "    print(len(train_loader), len(val_loader))\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=2, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--val-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=5, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "                        help='learning rate (default: 1.0)')\n",
    "parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                        help='Learning rate step gamma (default: 0.7)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "parser.add_argument('--no-mps', action='store_true', default=False,\n",
    "                        help='disables macOS GPU training')\n",
    "parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                        help='For Saving the current Model')\n",
    "parser.add_argument('--val_reduced', action='store_true', default=True,\n",
    "                        help='For Saving the current Model')\n",
    "parser.add_argument('--dataset', action='store_true', default=0,\n",
    "                        help='0 for MNIST, 1 for MNIST')\n",
    "parser.add_argument('--device', action='store_true', default=torch.device(\"cpu\"),\n",
    "                        help='.')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "DATASET = args.dataset\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
    "\n",
    "device = args.device\n",
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "val_kwargs = {'batch_size': args.val_batch_size}\n",
    "if 'cuda' in str(device):\n",
    "        cuda_kwargs = {'num_workers': 1, 'pin_memory': True, 'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        val_kwargs.update(cuda_kwargs)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "if DATASET==0:\n",
    "        mnist_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "elif DATASET==1:\n",
    "        mnist_dataset = datasets.FashionMNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "        \n",
    "if args.val_reduced:\n",
    "        sampled_indices = torch.randperm(len(mnist_dataset))[:2000]\n",
    "        mnist_dataset = Subset(mnist_dataset, sampled_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task 1 labeling\n",
    "task1_classes = [0, 1, 2, 3, 4, 9]\n",
    "# Check the unique labels in your dataset to make sure they are integers\n",
    "unique_labels = set(label for _, label in mnist_dataset)\n",
    "print(\"Unique Labels in Dataset:\", unique_labels)\n",
    "# Make sure labels are integers; if not, convert them to integers\n",
    "mnist_dataset = [(image, int(label)) for image, label in mnist_dataset]\n",
    "task1_indices = [i for i, (_, label) in enumerate(mnist_dataset) if label in task1_classes]\n",
    "task1_dataset = Subset(mnist_dataset, task1_indices)\n",
    "print(\"Selected labels for Task 1:\", set(label for _, label in task1_dataset))\n",
    "train_size_task1 = int(0.8 * len(task1_indices))\n",
    "val_size_task1 = len(task1_indices) - train_size_task1\n",
    "train_loader_task1, val_loader_task1 = get_data_loaders(task1_dataset, \n",
    "                                                        train_size_task1, \n",
    "                                                        val_size_task1,\n",
    "                                                        train_kwargs, \n",
    "                                                        val_kwargs)\n",
    "model = models.Net_log_softmax(classes = len(task1_classes)).to(device)\n",
    "# model = models.AlexNet(classes = 6).to(device)\n",
    "# model = models.BaseModel(28 * 28, 100, 6).to(device)\n",
    "\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "\n",
    "all_predictions, all_labels = train_and_validate(args, model, device, \n",
    "                                                 train_loader_task1, \n",
    "                                                 val_loader_task1, \n",
    "                                                 optimizer, \n",
    "                                                 scheduler,\n",
    "                                                 title=\"Task 1: \", \n",
    "                                                 type_label=task1_classes,\n",
    "                                                 model_path= \"models/mnist_cnn_task1_MULTICLASS.pt\"\n",
    "                                                 )\n",
    "\n",
    "print(f\"import torch; print(f'CUDA version: {torch.version.cuda}\\nTorch version: {torch.__version__}\\ndevice count: {torch.cuda.device_count()}')\\nDevice:{device}\\nDataset:{DATASET}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing \n",
    "Let's evaluate the best model over the whole validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy, val_loss, all_predictions, all_labels  = validate(model, device, val_loader_task1,task1_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(all_predictions), np.unique(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.shape, all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = np.unique(np.concatenate((all_labels, all_predictions)))\n",
    "unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(all_labels, all_predictions, labels=unique_classes)\n",
    "conf_matrix = pd.DataFrame(confusion_mat, index=unique_classes, columns=unique_classes)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize your confusion matrix https://seaborn.pydata.org/generated/seaborn.heatmap.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "unique_classes = np.unique(np.concatenate((all_labels, all_predictions)))\n",
    "confusion_mat = confusion_matrix(all_labels, all_predictions, labels=unique_classes)\n",
    "conf_matrix = pd.DataFrame(confusion_mat, index=unique_classes, columns=unique_classes)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(5, 4))\n",
    "ax = sns.heatmap(conf_matrix, annot=True, cmap=sns.cubehelix_palette(as_cmap=True), linewidths=0.1, cbar=False)\n",
    "\n",
    "# Set labels and ticks\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "\n",
    "# Set x and y ticks using the unique classes\n",
    "ax.set_xticks(range(len(unique_classes)))\n",
    "ax.set_yticks(range(len(unique_classes)))\n",
    "\n",
    "# Set x and y ticks at the center of the cells\n",
    "ax.set_xticks([i + 0.5 for i in range(len(unique_classes))])\n",
    "ax.set_yticks([i + 0.5 for i in range(len(unique_classes))])\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, target_names=[str(c) for c in task1_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_loader_task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions(model, val_loader, device, type_label=None, dataset_type=1):\n",
    "    if type_label is None:\n",
    "        type_label = task1_classes\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            pred = output.argmax(dim=1)\n",
    "            pred = inverse_remap_target(pred, type_label)        \n",
    "            all_predictions.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "    # Convert predictions and labels to numpy arrays\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Create a 4x4 grid for visualization\n",
    "    num_rows = 4\n",
    "    num_cols = 4\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    for i in range(num_rows * num_cols):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        idx = np.random.randint(len(all_labels))\n",
    "        plt.imshow(data[idx].cpu().numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        # Use the class names instead of numeric labels for Fashion MNIST\n",
    "        if dataset_type == 1:\n",
    "            class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "            predicted_class = class_names[all_predictions[idx]]\n",
    "            actual_class = class_names[all_labels[idx]]\n",
    "        else:\n",
    "            predicted_class = all_predictions[idx]\n",
    "            actual_class = all_labels[idx]\n",
    "\n",
    "        plt.title(f'Pred: {predicted_class}\\nActual: {actual_class}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for Fashion MNIST dataset (DATASET=1)\n",
    "visualize_predictions(model, val_loader_task1, device, dataset_type=DATASET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "\n",
    "def plot_multiclass_roc_curve(all_labels, all_predictions):\n",
    "    # Step 1: Label Binarization\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    y_onehot = label_binarizer.fit_transform(all_labels)\n",
    "    all_predictions_hot = label_binarizer.transform(all_predictions)\n",
    "\n",
    "    # Step 2: Calculate ROC curves\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    unique_classes = range(y_onehot.shape[1])\n",
    "    for i in unique_classes:\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_onehot[:, i], all_predictions_hot[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Step 3: Plot ROC curves\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # Micro-average ROC curve\n",
    "    fpr_micro, tpr_micro, _ = roc_curve(y_onehot.ravel(), all_predictions_hot.ravel())\n",
    "    roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "    plt.plot(\n",
    "        fpr_micro,\n",
    "        tpr_micro,\n",
    "        label=f\"micro-average ROC curve (AUC = {roc_auc_micro:.2f})\",\n",
    "        color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    # Macro-average ROC curve\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in unique_classes]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in unique_classes:\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= len(unique_classes)\n",
    "    fpr_macro = all_fpr\n",
    "    tpr_macro = mean_tpr\n",
    "    roc_auc_macro = auc(fpr_macro, tpr_macro)\n",
    "    plt.plot(\n",
    "        fpr_macro,\n",
    "        tpr_macro,\n",
    "        label=f\"macro-average ROC curve (AUC = {roc_auc_macro:.2f})\",\n",
    "        color=\"navy\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    # Individual class ROC curves with unique colors\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_classes)))\n",
    "    for class_id, color in zip(unique_classes, colors):\n",
    "        plt.plot(\n",
    "            fpr[class_id],\n",
    "            tpr[class_id],\n",
    "            color=color,\n",
    "            label=f\"ROC curve for Class {class_id} (AUC = {roc_auc[class_id]:.2f})\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--', linewidth=2)  # Add diagonal line for reference\n",
    "    plt.axis(\"equal\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Extension of Receiver Operating Characteristic\\n to One-vs-Rest multiclass\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "    \n",
    "plot_multiclass_roc_curve(all_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on second task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2_classes = [5, 6, 7, 8, 9, 1]\n",
    "task2_indices = [i for i, (_, label) in enumerate(mnist_dataset) if label in task2_classes]\n",
    "task2_dataset = Subset(mnist_dataset, task2_indices)\n",
    "print(\"Selected labels for Task 2:\", set(label for _, label in task2_dataset))\n",
    "train_size_task2 = int(0.8 * len(task2_indices))\n",
    "val_size_task2 = len(task2_indices) - train_size_task2\n",
    "\n",
    "model_task2 = models.Net_log_softmax(classes = len(task2_classes)).to(device)\n",
    "# model_task2 = models.BaseModel(28 * 28, 100, 6).to(device)\n",
    "# model_task2 = models.AlexNet(classes = 6).to(device)\n",
    "model_state_dict_task1 = torch.load(\"models/mnist_cnn_task1_MULTICLASS.pt\")\n",
    "model_task2.load_state_dict(model_state_dict_task1) \n",
    "optimizer_task2 = optim.Adadelta(model_task2.parameters(), lr=args.lr)\n",
    "# optimizer_task2 = optim.Adadelta(model.parameters(), lr=1)\n",
    "# scheduler_task2 = StepLR(optimizer_task2, step_size=1, gamma=0.7)\n",
    "scheduler_task2 = StepLR(optimizer_task2, step_size=1, gamma=args.gamma)\n",
    "\n",
    "print(f\"MODEL TRAINING TASK #2\".center(60, \"-\"))\n",
    "\n",
    "train_loader_task2, val_loader_task2 = get_data_loaders(task2_dataset, train_size_task2, val_size_task2,train_kwargs, val_kwargs)\n",
    "\n",
    "train_and_validate(args, \n",
    "                   model_task2, \n",
    "                   device, \n",
    "                   train_loader_task2, \n",
    "                   val_loader_task2, \n",
    "                   optimizer_task2, \n",
    "                   scheduler_task2, \n",
    "                   title=\"Task 2: \", \n",
    "                   type_label= task2_classes,\n",
    "                   model_path=\"models/mnist_cnn_task2_MULTICLASS.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it over task-2 validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy, val_loss, all_predictions, all_labels = validate(model_task2, device, val_loader_task2,task2_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = np.unique(np.concatenate((all_labels, all_predictions)))\n",
    "confusion_mat = confusion_matrix(all_labels, all_predictions, labels=unique_classes)\n",
    "conf_matrix = pd.DataFrame(confusion_mat, index=unique_classes, columns=unique_classes)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(5, 4))\n",
    "ax = sns.heatmap(conf_matrix, annot=True, cmap=sns.cubehelix_palette(as_cmap=True), linewidths=0.1, cbar=False)\n",
    "\n",
    "# Set labels and ticks\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "\n",
    "# Set x and y ticks using the unique classes\n",
    "ax.set_xticks(range(len(unique_classes)))\n",
    "ax.set_yticks(range(len(unique_classes)))\n",
    "\n",
    "# Set x and y ticks at the center of the cells\n",
    "ax.set_xticks([i + 0.5 for i in range(len(unique_classes))])\n",
    "ax.set_yticks([i + 0.5 for i in range(len(unique_classes))])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "np.unique(all_predictions), np.unique(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(all_predictions), np.unique(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model, val_loader_task2, device, dataset_type=DATASET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, target_names=[str(c) for c in task2_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model_task2, val_loader_task2, device, dataset_type=DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc_curve(all_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model again on task 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy, val_loss, all_predictions, all_labels  = validate(model_task2, device, val_loader_task1, task1_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the model can be loaded using the best stored model trained on task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task1_adapted = models.Net_log_softmax(classes=len(task1_classes)).to(device)\n",
    "model_state_dict_task2 = torch.load(\"models/mnist_cnn_task2_MULTICLASS.pt\")\n",
    "model_task1_adapted.load_state_dict(model_state_dict_task2.copy()) \n",
    "test_accuracy, test_loss, all_predictions, all_labels  = validate(model_task1_adapted, device, val_loader_task1, task1_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(all_predictions), np.unique(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, test_loss, all_predictions, all_labels = validate(model_task2, device,  val_loader_task1)\n",
    "confusion_mat = confusion_matrix(all_labels, all_predictions )\n",
    "conf_matrix = pd.DataFrame(confusion_mat)\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(5, 4))\n",
    "ax = sns.heatmap(conf_matrix,annot=True,  cmap=sns.cubehelix_palette(as_cmap=True), linewidths=0.1, cbar=False)\n",
    "\n",
    "# Set labels and ticks  \n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "ax.set_xticklabels(range(confusion_mat.shape[0]), rotation=45, ha='right')\n",
    "ax.set_yticklabels(range(confusion_mat.shape[0]), rotation=0)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, target_names=[str(c) for c in task1_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model_task1_adapted, val_loader_task1, device, dataset_type=DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model_task2, val_loader_task1, device, dataset_type=DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc_curve(all_labels, all_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sebasmos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
