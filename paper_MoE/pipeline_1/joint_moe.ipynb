{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ebed7c43-fa94-46f4-b5ce-3a193697dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  Dependencies\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "from river import tree, naive_bayes\n",
    "from river.datasets import synth\n",
    "import matplotlib.pyplot as plt\n",
    "from river import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from capymoa.stream.generator import LEDGeneratorDrift, LEDGenerator\n",
    "from capymoa.stream.drift import DriftStream, AbruptDrift, GradualDrift\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  CONFIG - same as pipeline 2\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TOTAL_SAMPLES   = 1_000_000          # change for quick tests\n",
    "TRAIN_RATIO     = 0.80\n",
    "NUM_CLASSES     = 10\n",
    "INPUT_DIM       = 24                 # 7 relevant + 17 irrelevant\n",
    "BATCH           = 256\n",
    "EPOCHS          = 75\n",
    "LR              = 2e-3\n",
    "SEED_STREAM     = 112\n",
    "SEED_TORCH      = 42\n",
    "torch.manual_seed(SEED_TORCH)\n",
    "random.seed(SEED_TORCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5d80c6b1-ba9c-4451-873a-c9bbfa658a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from capymoa.stream import MOAStream\n",
    "from moa.streams import ConceptDriftStream\n",
    "cli = \"-s (ConceptDriftStream -s (generators.LEDGeneratorDrift -d 1)   -d (ConceptDriftStream -s (generators.LEDGeneratorDrift -d 3) -d (ConceptDriftStream -s (generators.LEDGeneratorDrift -d 5)  -d (generators.LEDGeneratorDrift -d 7) -w 50000 -p 250000 ) -w 50000 -p 250000 ) -w 50000 -p 250000)\"\n",
    "led_g_stream = MOAStream(moa_stream=ConceptDriftStream(), CLI=cli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e67539e9-cd47-4f40-ab84-4f392f245c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "led_g_stream.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3b7d76c2-32c4-4b34-b5e8-81b409d6e09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@relation 'generators.LEDGeneratorDrift '\n",
       "\n",
       "@attribute att1 {0,1}\n",
       "@attribute att2 {0,1}\n",
       "@attribute att3 {0,1}\n",
       "@attribute att4 {0,1}\n",
       "@attribute att5 {0,1}\n",
       "@attribute att6 {0,1}\n",
       "@attribute att7 {0,1}\n",
       "@attribute att8 {0,1}\n",
       "@attribute att9 {0,1}\n",
       "@attribute att10 {0,1}\n",
       "@attribute att11 {0,1}\n",
       "@attribute att12 {0,1}\n",
       "@attribute att13 {0,1}\n",
       "@attribute att14 {0,1}\n",
       "@attribute att15 {0,1}\n",
       "@attribute att16 {0,1}\n",
       "@attribute att17 {0,1}\n",
       "@attribute att18 {0,1}\n",
       "@attribute att19 {0,1}\n",
       "@attribute att20 {0,1}\n",
       "@attribute att21 {0,1}\n",
       "@attribute att22 {0,1}\n",
       "@attribute att23 {0,1}\n",
       "@attribute att24 {0,1}\n",
       "@attribute class {0,1,2,3,4,5,6,7,8,9}\n",
       "\n",
       "@data"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = led_g_stream.get_schema()\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b93b7529-cc90-477a-b5dd-d161c0c894c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstream = list(\\n    synth.LEDDrift(\\n        seed                = SEED_STREAM,\\n        noise_percentage    = 0.10,\\n        irrelevant_features = True,\\n        n_drift_features    = 7\\n    ).take(TOTAL_SAMPLES)\\n)\\n\\nTOTAL_SAMPLES = 1_000_000          # match the ARF paper\\nstream = list(led_g(seed=42))[:TOTAL_SAMPLES]\\n\\nprint(f\"Loaded LED-g ARF stream âœ {len(stream):,} samples\")\\n# helper: dictâ†’24-float vector\\nd2v = lambda d: np.fromiter(d.values(), dtype=np.float32, count=INPUT_DIM)\\n'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  LOAD STREAM (River)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\"\"\"\n",
    "stream = list(\n",
    "    synth.LEDDrift(\n",
    "        seed                = SEED_STREAM,\n",
    "        noise_percentage    = 0.10,\n",
    "        irrelevant_features = True,\n",
    "        n_drift_features    = 7\n",
    "    ).take(TOTAL_SAMPLES)\n",
    ")\n",
    "\n",
    "TOTAL_SAMPLES = 1_000_000          # match the ARF paper\n",
    "stream = list(led_g(seed=42))[:TOTAL_SAMPLES]\n",
    "\n",
    "print(f\"Loaded LED-g ARF stream âœ {len(stream):,} samples\")\n",
    "# helper: dictâ†’24-float vector\n",
    "d2v = lambda d: np.fromiter(d.values(), dtype=np.float32, count=INPUT_DIM)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a40b289-a750-4222-928f-2f1f9980ce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 100,000  |  Burn-in: 10,000  |  Rest: 90,000\n"
     ]
    }
   ],
   "source": [
    "BURN_IN     = int(0.1 * TOTAL_SAMPLES)         # number of initial samples used only for clustering\n",
    "MAX_K       = 15             # search k = 1 â€¦ MAX_K\n",
    "SAMPLE_FRAC = 0.05           # sample 25 % of burn-in for PCA + GMM/Kmeans\n",
    "\n",
    "\n",
    "# 3-A) Carve out burn-in block\n",
    "stream        = list(stream_list)      # make it slice-able\n",
    "TOTAL         = len(stream_list)\n",
    "assert BURN_IN < TOTAL, \"BURN_IN must be less than total stream length\"\n",
    "burn_in_block = stream[:BURN_IN]\n",
    "rest_stream   = stream[BURN_IN:]  # will be used in Stage 1+2\n",
    "\n",
    "print(f\"Total samples: {TOTAL:,}  |  Burn-in: {len(burn_in_block):,}  |  Rest: {len(rest_stream):,}\")\n",
    "\n",
    "# 3-B) Draw an unsupervised sample (10% of burn-in) for clustering\n",
    "sample_len    = int(SAMPLE_FRAC * len(burn_in_block))\n",
    "indices       = random.sample(range(len(burn_in_block)), sample_len)\n",
    "cluster_block = [burn_in_block[i] for i in indices]\n",
    "\n",
    "# 3-C) Embed â†’ Standardize â†’ PCA â†’ Whiten\n",
    "#   (Assumes you have a function `d2v(x_dict)` that returns a 1Ã—INPUT_DIM numpy array)\n",
    "INPUT_DIM = 24  # adjust if your d2v output dimension is different\n",
    "\n",
    "X = np.stack([d2v(x_dict) for x_dict, _ in cluster_block])   # (sample_len Ã— INPUT_DIM)\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_std  = scaler.transform(X)\n",
    "pca    = PCA(whiten=True).fit(X_std)\n",
    "X_wht  = pca.transform(X_std)                                 # (sample_len Ã— INPUT_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acc38201-4788-4af9-9ca0-5f2ab71904ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0 complete â†’ selected n_experts = 20 (via BIC)\n"
     ]
    }
   ],
   "source": [
    "# 3-D) Fit GMMs for k in 1 â€¦ MAX_K, pick best by BIC\n",
    "bic_scores = []\n",
    "gmms       = []\n",
    "\n",
    "for k in range(1, MAX_K + 1):\n",
    "    gmm_candidate = GaussianMixture(\n",
    "        n_components=k,\n",
    "        covariance_type=\"diag\",\n",
    "        random_state=SEED_TORCH\n",
    "    ).fit(X_wht)\n",
    "    bic_scores.append(gmm_candidate.bic(X_wht))\n",
    "    gmms.append(gmm_candidate)\n",
    "\n",
    "best_k_index = int(np.argmin(bic_scores))  # index in [0 â€¦ MAX_K-1]\n",
    "n_experts    = best_k_index + 1            # because k started at 1\n",
    "gmm          = gmms[best_k_index]          # optional, if you want cluster IDs later\n",
    "\n",
    "print(f\"Stage 0 complete â†’ selected n_experts = {n_experts} (via BIC)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a6a8843-1d81-4bdf-80f0-a639f26ec0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 2  |  silhouette=0.0284\n",
      "k= 3  |  silhouette=0.0424\n",
      "k= 4  |  silhouette=0.0468\n",
      "k= 5  |  silhouette=0.0470\n",
      "k= 6  |  silhouette=0.0490\n",
      "k= 7  |  silhouette=0.0526\n",
      "k= 8  |  silhouette=0.0534\n",
      "k= 9  |  silhouette=0.0462\n",
      "k=10  |  silhouette=0.0471\n",
      "k=11  |  silhouette=0.0511\n",
      "k=12  |  silhouette=0.0485\n",
      "k=13  |  silhouette=0.0414\n",
      "k=14  |  silhouette=0.0448\n",
      "k=15  |  silhouette=0.0427\n",
      "k=16  |  silhouette=0.0422\n",
      "k=17  |  silhouette=0.0419\n",
      "k=18  |  silhouette=0.0402\n",
      "k=19  |  silhouette=0.0401\n",
      "k=20  |  silhouette=0.0390\n",
      "Stage 0 complete â†’ selected n_experts = 8 (highest silhouette = 0.0534)\n"
     ]
    }
   ],
   "source": [
    "# 0-D) K-means sweep  (k = 2 â€¦ MAX_K)\n",
    "best_k          = 1            # fallback if all silhouettes invalid\n",
    "best_score      = -1.0\n",
    "kmeans_models   = {}\n",
    "\n",
    "for k in range(2, MAX_K + 1):\n",
    "    km = KMeans(n_clusters=k, random_state=SEED_TORCH, n_init=\"auto\").fit(X_wht)\n",
    "    kmeans_models[k] = km\n",
    "    try:\n",
    "        score = silhouette_score(X_wht, km.labels_)\n",
    "    except ValueError:          # rare case: silhouette undefined\n",
    "        score = -1\n",
    "    print(f\"k={k:2d}  |  silhouette={score:.4f}\")\n",
    "    if score > best_score:\n",
    "        best_score, best_k = score, k\n",
    "\n",
    "n_experts = best_k\n",
    "kmeans    = kmeans_models[best_k]\n",
    "\n",
    "print(f\"Stage 0 complete â†’ selected n_experts = {n_experts} (highest silhouette = {best_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e409bb16-c8dd-47dd-9384-f15c2580bfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 samples]  router CE: 0.0000   pipeline acc: 0.0000\n",
      "[10,000 samples]  router CE: 218.8125   pipeline acc: 0.7371\n",
      "[20,000 samples]  router CE: 105.3284   pipeline acc: 0.7381\n",
      "[30,000 samples]  router CE: 69.9073   pipeline acc: 0.7400\n",
      "[40,000 samples]  router CE: 60.2030   pipeline acc: 0.7326\n",
      "[50,000 samples]  router CE: 43.1122   pipeline acc: 0.7322\n",
      "[60,000 samples]  router CE: 35.1811   pipeline acc: 0.7324\n",
      "[70,000 samples]  router CE: 29.0175   pipeline acc: 0.7339\n",
      "[80,000 samples]  router CE: 24.8829   pipeline acc: 0.7348\n",
      "[90,000 samples]  router CE: 22.9423   pipeline acc: 0.7349\n",
      "[100,000 samples]  router CE: 20.1287   pipeline acc: 0.7356\n",
      "[110,000 samples]  router CE: 19.5903   pipeline acc: 0.7350\n",
      "[120,000 samples]  router CE: 17.7454   pipeline acc: 0.7347\n",
      "[130,000 samples]  router CE: 15.9922   pipeline acc: 0.7348\n",
      "[140,000 samples]  router CE: 14.4850   pipeline acc: 0.7352\n",
      "[150,000 samples]  router CE: 13.6058   pipeline acc: 0.7355\n",
      "[160,000 samples]  router CE: 13.9922   pipeline acc: 0.7355\n",
      "[170,000 samples]  router CE: 14.2260   pipeline acc: 0.7348\n",
      "[180,000 samples]  router CE: 11.9030   pipeline acc: 0.7353\n",
      "[190,000 samples]  router CE: 11.6009   pipeline acc: 0.7353\n",
      "[200,000 samples]  router CE: 11.7077   pipeline acc: 0.7352\n",
      "[210,000 samples]  router CE: 10.5840   pipeline acc: 0.7356\n",
      "[220,000 samples]  router CE: 10.0615   pipeline acc: 0.7358\n",
      "[230,000 samples]  router CE: 9.4253   pipeline acc: 0.7361\n",
      "[240,000 samples]  router CE: 9.3207   pipeline acc: 0.7360\n",
      "[250,000 samples]  router CE: 8.8933   pipeline acc: 0.7362\n",
      "[260,000 samples]  router CE: 8.4922   pipeline acc: 0.7363\n",
      "[270,000 samples]  router CE: 8.1856   pipeline acc: 0.7364\n",
      "[280,000 samples]  router CE: 8.0834   pipeline acc: 0.7362\n",
      "[290,000 samples]  router CE: 7.6200   pipeline acc: 0.7363\n",
      "[300,000 samples]  router CE: 7.4185   pipeline acc: 0.7363\n",
      "[310,000 samples]  router CE: 6.8095   pipeline acc: 0.7365\n",
      "[320,000 samples]  router CE: 6.8044   pipeline acc: 0.7366\n",
      "[330,000 samples]  router CE: 6.6046   pipeline acc: 0.7366\n",
      "[340,000 samples]  router CE: 6.2081   pipeline acc: 0.7367\n",
      "[350,000 samples]  router CE: 5.9558   pipeline acc: 0.7369\n",
      "[360,000 samples]  router CE: 5.9673   pipeline acc: 0.7369\n",
      "[370,000 samples]  router CE: 5.7250   pipeline acc: 0.7370\n",
      "[380,000 samples]  router CE: 5.5801   pipeline acc: 0.7370\n",
      "[390,000 samples]  router CE: 5.4754   pipeline acc: 0.7370\n",
      "[400,000 samples]  router CE: 5.3007   pipeline acc: 0.7371\n",
      "[410,000 samples]  router CE: 4.9078   pipeline acc: 0.7371\n",
      "[420,000 samples]  router CE: 5.0192   pipeline acc: 0.7372\n",
      "[430,000 samples]  router CE: 4.9684   pipeline acc: 0.7372\n",
      "[440,000 samples]  router CE: 4.7770   pipeline acc: 0.7373\n",
      "[450,000 samples]  router CE: 4.5937   pipeline acc: 0.7375\n",
      "[460,000 samples]  router CE: 4.6518   pipeline acc: 0.7375\n",
      "[470,000 samples]  router CE: 4.4943   pipeline acc: 0.7374\n",
      "[480,000 samples]  router CE: 4.5475   pipeline acc: 0.7374\n",
      "[490,000 samples]  router CE: 4.2205   pipeline acc: 0.7375\n",
      "[500,000 samples]  router CE: 4.2392   pipeline acc: 0.7376\n",
      "[510,000 samples]  router CE: 4.1993   pipeline acc: 0.7377\n",
      "[520,000 samples]  router CE: 4.1537   pipeline acc: 0.7377\n",
      "[530,000 samples]  router CE: 4.0673   pipeline acc: 0.7377\n",
      "[540,000 samples]  router CE: 3.7876   pipeline acc: 0.7378\n",
      "[550,000 samples]  router CE: 3.7137   pipeline acc: 0.7378\n",
      "[560,000 samples]  router CE: 3.6269   pipeline acc: 0.7379\n",
      "[570,000 samples]  router CE: 3.6785   pipeline acc: 0.7379\n",
      "[580,000 samples]  router CE: 3.6324   pipeline acc: 0.7378\n",
      "[590,000 samples]  router CE: 3.5881   pipeline acc: 0.7378\n",
      "[600,000 samples]  router CE: 3.5339   pipeline acc: 0.7378\n",
      "[610,000 samples]  router CE: 3.3756   pipeline acc: 0.7378\n",
      "[620,000 samples]  router CE: 3.3310   pipeline acc: 0.7378\n",
      "[630,000 samples]  router CE: 3.2901   pipeline acc: 0.7378\n",
      "[640,000 samples]  router CE: 3.3703   pipeline acc: 0.7377\n",
      "[650,000 samples]  router CE: 3.0946   pipeline acc: 0.7378\n",
      "[660,000 samples]  router CE: 3.1013   pipeline acc: 0.7378\n",
      "[670,000 samples]  router CE: 3.0873   pipeline acc: 0.7377\n",
      "[680,000 samples]  router CE: 2.9269   pipeline acc: 0.7377\n",
      "[690,000 samples]  router CE: 2.9200   pipeline acc: 0.7378\n",
      "[700,000 samples]  router CE: 2.8096   pipeline acc: 0.7378\n",
      "[710,000 samples]  router CE: 2.9269   pipeline acc: 0.7378\n",
      "[720,000 samples]  router CE: 2.7418   pipeline acc: 0.7380\n",
      "[730,000 samples]  router CE: 2.6900   pipeline acc: 0.7381\n",
      "[740,000 samples]  router CE: 2.6838   pipeline acc: 0.7382\n",
      "[750,000 samples]  router CE: 2.7341   pipeline acc: 0.7382\n",
      "[760,000 samples]  router CE: 2.6542   pipeline acc: 0.7382\n",
      "[770,000 samples]  router CE: 2.5667   pipeline acc: 0.7382\n",
      "[780,000 samples]  router CE: 2.6268   pipeline acc: 0.7383\n",
      "[790,000 samples]  router CE: 2.5905   pipeline acc: 0.7382\n",
      "[800,000 samples]  router CE: 2.6745   pipeline acc: 0.7382\n",
      "[810,000 samples]  router CE: 2.4542   pipeline acc: 0.7382\n",
      "[820,000 samples]  router CE: 2.4896   pipeline acc: 0.7382\n",
      "[830,000 samples]  router CE: 2.4831   pipeline acc: 0.7382\n",
      "[840,000 samples]  router CE: 2.3721   pipeline acc: 0.7383\n",
      "[850,000 samples]  router CE: 2.4016   pipeline acc: 0.7382\n",
      "[860,000 samples]  router CE: 2.2918   pipeline acc: 0.7383\n",
      "[870,000 samples]  router CE: 2.3286   pipeline acc: 0.7383\n",
      "[880,000 samples]  router CE: 2.3310   pipeline acc: 0.7383\n",
      "[890,000 samples]  router CE: 2.2982   pipeline acc: 0.7383\n",
      "[900,000 samples]  router CE: 2.1369   pipeline acc: 0.7383\n",
      "[910,000 samples]  router CE: 2.2315   pipeline acc: 0.7383\n",
      "[920,000 samples]  router CE: 2.1865   pipeline acc: 0.7382\n",
      "[930,000 samples]  router CE: 2.2442   pipeline acc: 0.7382\n",
      "[940,000 samples]  router CE: 2.1823   pipeline acc: 0.7381\n",
      "[950,000 samples]  router CE: 2.1494   pipeline acc: 0.7381\n",
      "[960,000 samples]  router CE: 2.1512   pipeline acc: 0.7381\n",
      "[970,000 samples]  router CE: 2.1036   pipeline acc: 0.7381\n",
      "[980,000 samples]  router CE: 2.0778   pipeline acc: 0.7381\n",
      "[990,000 samples]  router CE: 2.0405   pipeline acc: 0.7381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can not access instrumentation environment.\n",
      "Please check if jar file containing SizeOfAgent class is \n",
      "specified in the java's \"-javaagent\" command line argument.\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by sizeof.agent.SizeOfAgent (file:/home/miguel/miniconda3/envs/moe_paper/lib/python3.10/site-packages/capymoa/jar/moa.jar) to field java.util.ArrayList.elementData\n",
      "WARNING: Please consider reporting this to the maintainers of sizeof.agent.SizeOfAgent\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ train-window accuracy: 0.738061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n# 4.  Hold-out evaluation  (last 10 %)\\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nrouter.eval()\\nhold_acc = metrics.Accuracy()\\n\\nwith torch.no_grad():\\n    for x_dict, y_true in hold_stream:\\n        x_vec = d2v(x_dict)\\n        logits  = router(to_tensor(x_vec).unsqueeze(0))\\n        weights = torch.softmax(logits, dim=1)\\n        exp_probs = []\\n        for e in experts.values():\\n            pdict = e.predict_proba_one(x_dict) or {c: 1/NUM_CLASSES for c in CLASSES}\\n            exp_probs.append([pdict.get(c, 0.0) for c in CLASSES])\\n        exp_probs = torch.tensor(exp_probs)\\n        mix_prob  = torch.mm(weights, exp_probs)\\n        y_hat     = CLASSES[int(torch.argmax(mix_prob))]\\n        hold_acc.update(y_true, y_hat)\\n\\nprint(\"ğŸ hold-out (10 %) accuracy:\", hold_acc.get())\\n'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1.  Hyper-params & boiler-plate\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "from capymoa.classifier import HoeffdingTree\n",
    "\n",
    "\n",
    "n_experts = 15\n",
    "\n",
    "TOP_K         = 3            # update the K heaviest-weighted experts\n",
    "PRINT_EVERY   = 10_000\n",
    "CLASSES       = list(range(NUM_CLASSES))\n",
    "\n",
    "def to_tensor(x):\n",
    "    return torch.tensor(x, dtype=torch.float32)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2.  Initialise experts and router\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "experts = {i: HoeffdingTree(schema=schema, grace_period=50, confidence=1e-07, binary_split=False, stop_mem_management=False) for i in range(n_experts)}\n",
    "\n",
    "class RouterMLP(nn.Module):\n",
    "    def __init__(self, in_dim=INPUT_DIM, h=256, out_dim=n_experts):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, h), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(h, h // 2), nn.ReLU(),\n",
    "            nn.Linear(h // 2, out_dim)\n",
    "        )\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "router = RouterMLP()\n",
    "opt    = torch.optim.Adam(router.parameters(), lr=LR)\n",
    "nll    = nn.NLLLoss(reduction=\"mean\")\n",
    "\n",
    "pipeline_acc = metrics.Accuracy()\n",
    "running_loss = 0.0\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3.  Online joint-training loop \n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "router.train()\n",
    "micro_X, micro_y = [], []\n",
    "\n",
    "for t in range(TOTAL_SAMPLES):\n",
    "    # 3-A  Embed sample\n",
    "\n",
    "    instance = stream.next_instance()\n",
    "    x_vec = instance.x\n",
    "    y_true = instance.y_index\n",
    "    x_t   = to_tensor(x_vec).unsqueeze(0)         # 1Ã—24\n",
    "\n",
    "    # 3-B  Router forward\n",
    "    logits  = router(x_t) # 1Ã—n_experts\n",
    "    #tau0, tau_min, decay_steps = 2.0, 0.7, 80_000   \n",
    "    #tau = max(tau_min, tau0 * (1 - t / decay_steps)) # linear-cosine also works\n",
    "    #weights = torch.softmax(logits / tau, dim=1)     # replaces previous softmax                       \n",
    "    weights = torch.softmax(logits, dim=1)        # 1Ã—n_experts\n",
    "\n",
    "    # 3-C  Gather expertsâ€™ probability vectors\n",
    "    exp_probs = []\n",
    "    for e in experts.values():\n",
    "        p_list = e.predict_proba(instance) or [1/NUM_CLASSES for c in CLASSES]\n",
    "        if p_list is None:                            # brand-new leaf\n",
    "            padded_p_list = [1 / NUM_CLASSES] * NUM_CLASSES  # uniform prior\n",
    "        elif len(p_list) < NUM_CLASSES:               # seen some classes\n",
    "            \n",
    "            padded_p_list = list(p_list) + [0.0] * (NUM_CLASSES - len(list(p_list)))\n",
    "        else:                                      # already full length\n",
    "            padded_p_list = list(p_list)\n",
    "        exp_probs.append(padded_p_list)\n",
    "    exp_probs = torch.tensor(exp_probs)           # n_experts Ã— C\n",
    "\n",
    "    mix_prob = torch.mm(weights, exp_probs) + 1e-9\n",
    "    log_mix  = (mix_prob / mix_prob.sum()).log()  # 1Ã—C log-probs\n",
    "\n",
    "    # 3-D  Accumulate mini-batch for router update\n",
    "    micro_X.append(log_mix)\n",
    "    micro_y.append(y_true)\n",
    "    if len(micro_X) == BATCH:\n",
    "        batch_X = torch.cat(micro_X, dim=0)       # BÃ—C\n",
    "        batch_y = torch.tensor(micro_y)\n",
    "        loss = nll(batch_X, batch_y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        running_loss += loss.item() * BATCH\n",
    "        micro_X.clear(); micro_y.clear()\n",
    "\n",
    "    # 3-E  Top-K expert updates\n",
    "    with torch.no_grad():\n",
    "        topk_ids = torch.topk(weights, k=TOP_K, dim=1).indices.squeeze(0)\n",
    "    for eid in topk_ids.tolist():\n",
    "        experts[eid].train(instance)\n",
    "\n",
    "    # 3-F  Running metrics\n",
    "    y_hat = CLASSES[int(torch.argmax(mix_prob))]\n",
    "    pipeline_acc.update(y_true, y_hat)\n",
    "\n",
    "    if t % PRINT_EVERY == 0:\n",
    "        avg_ce = running_loss / max(1, (t // BATCH))\n",
    "        print(f\"[{t:,} samples]  router CE: {avg_ce:.4f}   \"\n",
    "              f\"pipeline acc: {pipeline_acc.get():.4f}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "print(\"ğŸ train-window accuracy:\", pipeline_acc.get())\n",
    "\n",
    "\"\"\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4.  Hold-out evaluation  (last 10 %)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "router.eval()\n",
    "hold_acc = metrics.Accuracy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_dict, y_true in hold_stream:\n",
    "        x_vec = d2v(x_dict)\n",
    "        logits  = router(to_tensor(x_vec).unsqueeze(0))\n",
    "        weights = torch.softmax(logits, dim=1)\n",
    "        exp_probs = []\n",
    "        for e in experts.values():\n",
    "            pdict = e.predict_proba_one(x_dict) or {c: 1/NUM_CLASSES for c in CLASSES}\n",
    "            exp_probs.append([pdict.get(c, 0.0) for c in CLASSES])\n",
    "        exp_probs = torch.tensor(exp_probs)\n",
    "        mix_prob  = torch.mm(weights, exp_probs)\n",
    "        y_hat     = CLASSES[int(torch.argmax(mix_prob))]\n",
    "        hold_acc.update(y_true, y_hat)\n",
    "\n",
    "print(\"ğŸ hold-out (10 %) accuracy:\", hold_acc.get())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d326c2-7733-4455-b9d6-e5dc6caf3a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74413b-399c-4245-9fa6-79cb598de640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
