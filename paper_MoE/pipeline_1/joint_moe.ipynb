{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebed7c43-fa94-46f4-b5ce-3a193697dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "#  Dependencies\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "from river import tree, naive_bayes\n",
    "from river.datasets import synth\n",
    "import matplotlib.pyplot as plt\n",
    "from river import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "#  CONFIG - same as pipeline 2\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "TOTAL_SAMPLES   = 100000          # change for quick tests\n",
    "TRAIN_RATIO     = 0.80\n",
    "NUM_CLASSES     = 10\n",
    "INPUT_DIM       = 24                 # 7 relevant + 17 irrelevant\n",
    "BATCH           = 256\n",
    "EPOCHS          = 75\n",
    "LR              = 3e-3\n",
    "SEED_STREAM     = 112\n",
    "SEED_TORCH      = 42\n",
    "torch.manual_seed(SEED_TORCH)\n",
    "random.seed(SEED_TORCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b93b7529-cc90-477a-b5dd-d161c0c894c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "#  LOAD STREAM\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "stream = list(\n",
    "    synth.LEDDrift(\n",
    "        seed                = SEED_STREAM,\n",
    "        noise_percentage    = 0.10,\n",
    "        irrelevant_features = True,\n",
    "        n_drift_features    = 7\n",
    "    ).take(TOTAL_SAMPLES)\n",
    ")\n",
    "\n",
    "half               = TOTAL_SAMPLES // 2\n",
    "exp_cluster = TOTAL_SAMPLES // 10\n",
    "\n",
    "# helper: dict→24-float vector\n",
    "d2v = lambda d: np.fromiter(d.values(), dtype=np.float32, count=INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a40b289-a750-4222-928f-2f1f9980ce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0 ✔  selected n_experts = 9 (BIC)\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_FRAC  = 0.10                     # 10 % of the training window\n",
    "\n",
    "# 0-a  Split once:  90 % train | 10 % hold-out\n",
    "stream        = list(stream)            # make slice-able\n",
    "TOTAL         = len(stream)\n",
    "split_at      = int(0.9 * TOTAL)\n",
    "train_stream  = stream[:split_at]\n",
    "hold_stream   = stream[split_at:]       # untouched until final eval\n",
    "\n",
    "# 0-b  Draw a small uniform sample from the *train* part\n",
    "sample_len    = int(SAMPLE_FRAC * len(train_stream))\n",
    "random.seed(SEED_TORCH)\n",
    "sample_idx    = random.sample(range(len(train_stream)), sample_len)\n",
    "cluster_block = [train_stream[i] for i in sample_idx]\n",
    "\n",
    "# 0-c  Embed  ➜  scale  ➜  whiten\n",
    "X   = np.stack([d2v(x) for x, _ in cluster_block])\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_std  = scaler.transform(X)\n",
    "pca    = PCA(whiten=True).fit(X_std)\n",
    "X_wht  = pca.transform(X_std)\n",
    "\n",
    "# 0-d  Fit candidate GMMs and pick k with lowest BIC\n",
    "bic_scores, gmms = [], []\n",
    "for k in range(1, NUM_CLASSES + 1):\n",
    "    g = GaussianMixture(n_components=k, covariance_type=\"diag\",\n",
    "                        random_state=SEED_TORCH).fit(X_wht)\n",
    "    bic_scores.append(g.bic(X_wht))\n",
    "    gmms.append(g)\n",
    "\n",
    "best_k      = int(np.argmin(bic_scores)) + 1   # +1 because range starts at 1\n",
    "gmm         = gmms[best_k - 1]                 # keep if you still want cluster IDs\n",
    "n_experts   = best_k                           # ← the number you will use\n",
    "\n",
    "print(f\"Stage 0 ✔  selected n_experts = {n_experts} (BIC)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e409bb16-c8dd-47dd-9384-f15c2580bfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,000 samples]  router CE: 425.0343   pipeline acc: 0.5630\n",
      "[2,000 samples]  router CE: 133.7576   pipeline acc: 0.6535\n",
      "[3,000 samples]  router CE: 91.3693   pipeline acc: 0.6853\n",
      "[4,000 samples]  router CE: 59.4474   pipeline acc: 0.7030\n",
      "[5,000 samples]  router CE: 46.8206   pipeline acc: 0.7124\n",
      "[6,000 samples]  router CE: 38.0124   pipeline acc: 0.7200\n",
      "[7,000 samples]  router CE: 32.0989   pipeline acc: 0.7260\n",
      "[8,000 samples]  router CE: 27.3526   pipeline acc: 0.7305\n",
      "[9,000 samples]  router CE: 24.1677   pipeline acc: 0.7352\n",
      "[10,000 samples]  router CE: 23.6133   pipeline acc: 0.7365\n",
      "[11,000 samples]  router CE: 15.7349   pipeline acc: 0.7397\n",
      "[12,000 samples]  router CE: 18.0157   pipeline acc: 0.7422\n",
      "[13,000 samples]  router CE: 17.6991   pipeline acc: 0.7449\n",
      "[14,000 samples]  router CE: 14.9804   pipeline acc: 0.7471\n",
      "[15,000 samples]  router CE: 15.0886   pipeline acc: 0.7476\n",
      "[16,000 samples]  router CE: 12.7112   pipeline acc: 0.7492\n",
      "[17,000 samples]  router CE: 13.1319   pipeline acc: 0.7503\n",
      "[18,000 samples]  router CE: 12.8807   pipeline acc: 0.7499\n",
      "[19,000 samples]  router CE: 11.8305   pipeline acc: 0.7497\n",
      "[20,000 samples]  router CE: 10.2172   pipeline acc: 0.7506\n",
      "[21,000 samples]  router CE: 9.5996   pipeline acc: 0.7509\n",
      "[22,000 samples]  router CE: 7.8767   pipeline acc: 0.7510\n",
      "[23,000 samples]  router CE: 9.4129   pipeline acc: 0.7520\n",
      "[24,000 samples]  router CE: 9.9538   pipeline acc: 0.7520\n",
      "[25,000 samples]  router CE: 8.9140   pipeline acc: 0.7520\n",
      "[26,000 samples]  router CE: 8.4625   pipeline acc: 0.7521\n",
      "[27,000 samples]  router CE: 7.1998   pipeline acc: 0.7532\n",
      "[28,000 samples]  router CE: 8.3722   pipeline acc: 0.7530\n",
      "[29,000 samples]  router CE: 8.0283   pipeline acc: 0.7529\n",
      "[30,000 samples]  router CE: 7.3137   pipeline acc: 0.7534\n",
      "[31,000 samples]  router CE: 6.6511   pipeline acc: 0.7537\n",
      "[32,000 samples]  router CE: 6.6234   pipeline acc: 0.7546\n",
      "[33,000 samples]  router CE: 5.4968   pipeline acc: 0.7542\n",
      "[34,000 samples]  router CE: 6.5136   pipeline acc: 0.7545\n",
      "[35,000 samples]  router CE: 5.7809   pipeline acc: 0.7552\n",
      "[36,000 samples]  router CE: 6.0875   pipeline acc: 0.7553\n",
      "[37,000 samples]  router CE: 6.2161   pipeline acc: 0.7552\n",
      "[38,000 samples]  router CE: 8.8262   pipeline acc: 0.7554\n",
      "[39,000 samples]  router CE: 6.2734   pipeline acc: 0.7555\n",
      "[40,000 samples]  router CE: 5.5443   pipeline acc: 0.7563\n",
      "[41,000 samples]  router CE: 5.2588   pipeline acc: 0.7566\n",
      "[42,000 samples]  router CE: 4.7311   pipeline acc: 0.7576\n",
      "[43,000 samples]  router CE: 3.5816   pipeline acc: 0.7581\n",
      "[44,000 samples]  router CE: 5.3428   pipeline acc: 0.7579\n",
      "[45,000 samples]  router CE: 5.0388   pipeline acc: 0.7579\n",
      "[46,000 samples]  router CE: 4.8181   pipeline acc: 0.7574\n",
      "[47,000 samples]  router CE: 4.9607   pipeline acc: 0.7574\n",
      "[48,000 samples]  router CE: 4.6124   pipeline acc: 0.7572\n",
      "[49,000 samples]  router CE: 4.0996   pipeline acc: 0.7573\n",
      "[50,000 samples]  router CE: 4.3926   pipeline acc: 0.7572\n",
      "[51,000 samples]  router CE: 4.0372   pipeline acc: 0.7574\n",
      "[52,000 samples]  router CE: 4.3368   pipeline acc: 0.7569\n",
      "[53,000 samples]  router CE: 3.9708   pipeline acc: 0.7570\n",
      "[54,000 samples]  router CE: 2.8871   pipeline acc: 0.7577\n",
      "[55,000 samples]  router CE: 3.8303   pipeline acc: 0.7577\n",
      "[56,000 samples]  router CE: 3.9918   pipeline acc: 0.7578\n",
      "[57,000 samples]  router CE: 3.7741   pipeline acc: 0.7576\n",
      "[58,000 samples]  router CE: 3.4097   pipeline acc: 0.7578\n",
      "[59,000 samples]  router CE: 3.5809   pipeline acc: 0.7576\n",
      "[60,000 samples]  router CE: 3.3812   pipeline acc: 0.7578\n",
      "[61,000 samples]  router CE: 3.2228   pipeline acc: 0.7579\n",
      "[62,000 samples]  router CE: 3.5202   pipeline acc: 0.7579\n",
      "[63,000 samples]  router CE: 3.4043   pipeline acc: 0.7580\n",
      "[64,000 samples]  router CE: 2.9952   pipeline acc: 0.7584\n",
      "[65,000 samples]  router CE: 2.2627   pipeline acc: 0.7588\n",
      "[66,000 samples]  router CE: 3.1696   pipeline acc: 0.7590\n",
      "[67,000 samples]  router CE: 3.2201   pipeline acc: 0.7593\n",
      "[68,000 samples]  router CE: 3.2361   pipeline acc: 0.7593\n",
      "[69,000 samples]  router CE: 3.0035   pipeline acc: 0.7594\n",
      "[70,000 samples]  router CE: 3.0312   pipeline acc: 0.7595\n",
      "[71,000 samples]  router CE: 2.9414   pipeline acc: 0.7595\n",
      "[72,000 samples]  router CE: 3.3445   pipeline acc: 0.7592\n",
      "[84,000 samples]  router CE: 2.4579   pipeline acc: 0.7595\n",
      "[85,000 samples]  router CE: 2.6055   pipeline acc: 0.7595\n",
      "[86,000 samples]  router CE: 2.0860   pipeline acc: 0.7593\n",
      "[87,000 samples]  router CE: 2.5116   pipeline acc: 0.7593\n",
      "[88,000 samples]  router CE: 2.7108   pipeline acc: 0.7592\n",
      "[89,000 samples]  router CE: 2.4395   pipeline acc: 0.7594\n",
      "[90,000 samples]  router CE: 2.4611   pipeline acc: 0.7594\n",
      "🏁 train-window accuracy: 0.7594222222222222\n",
      "🏁 hold-out (10 %) accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 1.  Hyper-params & boiler-plate\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "TOP_K         = 2            # update the K heaviest-weighted experts\n",
    "PRINT_EVERY   = 1_000\n",
    "CLASSES       = list(range(NUM_CLASSES))\n",
    "\n",
    "def to_tensor(x):\n",
    "    return torch.tensor(x, dtype=torch.float32)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 2.  Initialise experts and router\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "experts = {i: tree.HoeffdingTreeClassifier() for i in range(n_experts)}\n",
    "\n",
    "class RouterMLP(nn.Module):\n",
    "    def __init__(self, in_dim=INPUT_DIM, h=256, out_dim=n_experts):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, h), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(h, h // 2), nn.ReLU(),\n",
    "            nn.Linear(h // 2, out_dim)\n",
    "        )\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "router = RouterMLP()\n",
    "opt    = torch.optim.Adam(router.parameters(), lr=LR)\n",
    "nll    = nn.NLLLoss(reduction=\"mean\")\n",
    "\n",
    "pipeline_acc = metrics.Accuracy()\n",
    "running_loss = 0.0\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 3.  Online joint-training loop  (90 % train slice)\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "router.train()\n",
    "micro_X, micro_y = [], []\n",
    "\n",
    "for t, (x_dict, y_true) in enumerate(train_stream, 1):\n",
    "    # 3-A  Embed sample\n",
    "    x_vec = d2v(x_dict)\n",
    "    x_t   = to_tensor(x_vec).unsqueeze(0)         # 1×24\n",
    "\n",
    "    # 3-B  Router forward\n",
    "    logits  = router(x_t)                         # 1×n_experts\n",
    "    weights = torch.softmax(logits, dim=1)        # 1×n_experts\n",
    "\n",
    "    # 3-C  Gather experts’ probability vectors\n",
    "    exp_probs = []\n",
    "    for e in experts.values():\n",
    "        pdict = e.predict_proba_one(x_dict) or {c: 1/NUM_CLASSES for c in CLASSES}\n",
    "        exp_probs.append([pdict.get(c, 0.0) for c in CLASSES])\n",
    "    exp_probs = torch.tensor(exp_probs)           # n_experts × C\n",
    "\n",
    "    mix_prob = torch.mm(weights, exp_probs) + 1e-9\n",
    "    log_mix  = (mix_prob / mix_prob.sum()).log()  # 1×C log-probs\n",
    "\n",
    "    # 3-D  Accumulate mini-batch for router update\n",
    "    micro_X.append(log_mix)\n",
    "    micro_y.append(y_true)\n",
    "    if len(micro_X) == BATCH:\n",
    "        batch_X = torch.cat(micro_X, dim=0)       # B×C\n",
    "        batch_y = torch.tensor(micro_y)\n",
    "        loss = nll(batch_X, batch_y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        running_loss += loss.item() * BATCH\n",
    "        micro_X.clear(); micro_y.clear()\n",
    "\n",
    "    # 3-E  Top-K expert updates\n",
    "    with torch.no_grad():\n",
    "        topk_ids = torch.topk(weights, k=TOP_K, dim=1).indices.squeeze(0)\n",
    "    for eid in topk_ids.tolist():\n",
    "        experts[eid].learn_one(x_dict, y_true)\n",
    "\n",
    "    # 3-F  Running metrics\n",
    "    y_hat = CLASSES[int(torch.argmax(mix_prob))]\n",
    "    pipeline_acc.update(y_true, y_hat)\n",
    "\n",
    "    if t % PRINT_EVERY == 0:\n",
    "        avg_ce = running_loss / max(1, (t // BATCH))\n",
    "        print(f\"[{t:,} samples]  router CE: {avg_ce:.4f}   \"\n",
    "              f\"pipeline acc: {pipeline_acc.get():.4f}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "print(\"🏁 train-window accuracy:\", pipeline_acc.get())\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 4.  Hold-out evaluation  (last 10 %)\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "router.eval()\n",
    "hold_acc = metrics.Accuracy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_dict, y_true in hold_stream:\n",
    "        x_vec = d2v(x_dict)\n",
    "        logits  = router(to_tensor(x_vec).unsqueeze(0))\n",
    "        weights = torch.softmax(logits, dim=1)\n",
    "        exp_probs = []\n",
    "        for e in experts.values():\n",
    "            pdict = e.predict_proba_one(x_dict) or {c: 1/NUM_CLASSES for c in CLASSES}\n",
    "            exp_probs.append([pdict.get(c, 0.0) for c in CLASSES])\n",
    "        exp_probs = torch.tensor(exp_probs)\n",
    "        mix_prob  = torch.mm(weights, exp_probs)\n",
    "        y_hat     = CLASSES[int(torch.argmax(mix_prob))]\n",
    "        hold_acc.update(y_true, y_hat)\n",
    "\n",
    "print(\"🏁 hold-out (10 %) accuracy:\", hold_acc.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d326c2-7733-4455-b9d6-e5dc6caf3a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moe_paper",
   "language": "python",
   "name": "moe_paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
