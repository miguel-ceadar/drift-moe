{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564b911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── SPLITS ───────────────────────────────────────────\n",
      " Total samples         : 100,000\n",
      " Expert  train / val   : 40,000 / 10,000\n",
      " Router  train / val   : 40,000 / 10,000\n",
      "\n",
      "── EXPERT VALIDATION ACC (first 50 %) ──────────────\n",
      " Expert 0: 0.9583\n",
      " Expert 1: 0.9654\n",
      " Expert 2: 0.9712\n",
      " Expert 3: 0.9438\n",
      " Expert 4: 0.9663\n",
      " Expert 5: 0.9497\n",
      " Expert 6: 0.9581\n",
      " Expert 7: 0.9554\n",
      " Expert 8: 0.9370\n",
      " Expert 9: 0.9346\n",
      "\n",
      "Router-train usable samples            : 26,575\n",
      "Epoch 1/5 | router-train CE: 0.4322\n",
      "Epoch 2/5 | router-train CE: 0.0063\n",
      "Epoch 3/5 | router-train CE: 0.0082\n",
      "Epoch 4/5 | router-train CE: 0.0050\n",
      "Epoch 5/5 | router-train CE: 0.0045\n",
      "\n",
      "🏁  Pipeline accuracy on router-val slice: 0.6725\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Mixture-of-Experts pipeline for LED_a\n",
    "\n",
    "STAGE 1  (first 50 % of the stream)\n",
    "    • split 80 / 20  → expert-train / expert-val\n",
    "    • train 10 one-vs-rest Hoeffding-Tree experts\n",
    "    • keep all 10 experts (we do NOT pre-discard any)\n",
    "\n",
    "STAGE 2  (second 50 % of the stream)\n",
    "    • split 80 / 20  → router-train / router-val\n",
    "    • for every sample in router-train, find **which expert(s) predict correctly**\n",
    "      – if ≥1 experts correct → pick the first correct ID as the target label  \n",
    "      – if 0 experts correct   → skip the sample (router can’t learn from it)\n",
    "    • train a 10-way soft-max MLP router on those (x, expert-id) pairs\n",
    "    • router-val:  router chooses an expert ► expert predicts ► measure accuracy\n",
    "\"\"\"\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "#  Dependencies\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "from river import tree, naive_bayes\n",
    "from river.datasets import synth\n",
    "import matplotlib.pyplot as plt\n",
    "from river import metrics\n",
    "from river import forest\n",
    "from river.datasets import synth\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "#  CONFIG\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "TOTAL_SAMPLES   = 100000          # change for quick tests\n",
    "TRAIN_RATIO     = 0.80\n",
    "NUM_CLASSES     = 10\n",
    "INPUT_DIM       = 24                 # 7 relevant + 17 irrelevant\n",
    "BATCH           = 256\n",
    "EPOCHS          = 5\n",
    "LR              = 3e-3\n",
    "SEED_STREAM     = 112\n",
    "SEED_TORCH      = 42\n",
    "torch.manual_seed(SEED_TORCH)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "#  LOAD STREAM  &  SPLIT\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "stream = list(\n",
    "    synth.LEDDrift(\n",
    "        seed                = SEED_STREAM,\n",
    "        noise_percentage    = 0.10,\n",
    "        irrelevant_features = True,\n",
    "        n_drift_features    = 7\n",
    "    ).take(TOTAL_SAMPLES)\n",
    ")\n",
    "\n",
    "half               = TOTAL_SAMPLES // 2\n",
    "expert_block       = stream[:half]\n",
    "router_block       = stream[half:]\n",
    "\n",
    "exp_train_sz       = int(len(expert_block)  * TRAIN_RATIO)\n",
    "rtr_train_sz       = int(len(router_block)  * TRAIN_RATIO)\n",
    "\n",
    "exp_train, exp_val = expert_block[:exp_train_sz], expert_block[exp_train_sz:]\n",
    "rtr_train, rtr_val = router_block[:rtr_train_sz], router_block[rtr_train_sz:]\n",
    "\n",
    "print(\"── SPLITS ───────────────────────────────────────────\")\n",
    "print(f\" Total samples         : {TOTAL_SAMPLES:,}\")\n",
    "print(f\" Expert  train / val   : {len(exp_train):,} / {len(exp_val):,}\")\n",
    "print(f\" Router  train / val   : {len(rtr_train):,} / {len(rtr_val):,}\")\n",
    "\n",
    "# helper: dict→24-float vector\n",
    "d2v = lambda d: np.fromiter(d.values(), dtype=np.float32, count=INPUT_DIM)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "#  STAGE 1  – TRAIN 10 EXPERTS\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "experts   = {cid: tree.HoeffdingTreeClassifier() for cid in range(NUM_CLASSES)}\n",
    "exp_val_acc = {cid: metrics.Accuracy()           for cid in range(NUM_CLASSES)}\n",
    "\n",
    "for x,y in exp_train:\n",
    "    for cid,e in experts.items():\n",
    "        e.learn_one(x, int(y==cid))\n",
    "\n",
    "for x,y in exp_val:\n",
    "    for cid,e in experts.items():\n",
    "        exp_val_acc[cid].update(int(y==cid), e.predict_one(x))\n",
    "\n",
    "print(\"\\n── EXPERT VALIDATION ACC (first 50 %) ──────────────\")\n",
    "for cid in range(NUM_CLASSES):\n",
    "    print(f\" Expert {cid}: {exp_val_acc[cid].get():.4f}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "#  STAGE 2  – BUILD ROUTER TRAIN SET\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "router_X, router_y = [], []\n",
    "\n",
    "for x_dict, y_true in rtr_train:\n",
    "    correct_ids = [cid for cid,e in experts.items()\n",
    "                   if e.predict_one(x_dict)==1 and y_true==cid]\n",
    "    if not correct_ids:           # skip sample if no expert is correct\n",
    "        continue\n",
    "    router_X.append(d2v(x_dict))\n",
    "    router_y.append(correct_ids[0])   # choose first correct expert id\n",
    "\n",
    "router_X = np.stack(router_X)\n",
    "router_y = np.array(router_y, dtype=np.int64)\n",
    "print(f\"\\nRouter-train usable samples            : {len(router_y):,}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "#  ROUTER MLP\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "class TorchDS(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = torch.tensor(X)\n",
    "        self.y = torch.tensor(y)\n",
    "    def __len__(self):  return len(self.X)\n",
    "    def __getitem__(self,i): return self.X[i], self.y[i]\n",
    "\n",
    "train_dl = DataLoader(TorchDS(router_X, router_y), batch_size=BATCH, shuffle=True)\n",
    "\n",
    "class RouterMLP(nn.Module):\n",
    "    def __init__(self, in_dim=INPUT_DIM, hidden=128, out_dim=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim,hidden), nn.SiLU(),\n",
    "            nn.Linear(hidden,hidden), nn.SiLU(),\n",
    "            nn.Linear(hidden,out_dim)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "router = RouterMLP()\n",
    "opt    = torch.optim.Adam(router.parameters(), lr=LR)\n",
    "ce     = nn.CrossEntropyLoss()\n",
    "print(\"\\n── ROUTER TRAINING ACC (Second 50 %) ──────────────\")\n",
    "router.train()\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    running = 0.0\n",
    "    for xb,yb in train_dl:\n",
    "        opt.zero_grad()\n",
    "        loss = ce(router(xb), yb)\n",
    "        loss.backward(); opt.step()\n",
    "        running += loss.item()*len(xb)\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | router-train CE: {running/len(train_dl.dataset):.4f}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "#  FINAL EVALUATION ON router-val\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "router.eval()\n",
    "pipeline_acc = metrics.Accuracy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_dict, y_true in rtr_val:\n",
    "        logits = router(torch.tensor(d2v(x_dict))).softmax(0)\n",
    "        eid    = int(torch.argmax(logits).item())          # expert chosen\n",
    "        final  = eid if experts[eid].predict_one(x_dict)==1 else -1\n",
    "        pipeline_acc.update(y_true, final)\n",
    "\n",
    "print(f\"\\n🏁  Pipeline accuracy on router-val slice: \"\n",
    "      f\"{pipeline_acc.get():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5daa48b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── SPLITS ───────────────────────────────────────────\n",
      " total samples         : 100,000\n",
      " expert  train / val   : 40,000 / 10,000\n",
      " router  train / val   : 40,000 / 10,000\n",
      "\n",
      "── EXPERT VALID ACC (first 50 %) ───────────────────\n",
      " expert 0: 0.9583\n",
      " expert 1: 0.9654\n",
      " expert 2: 0.9712\n",
      " expert 3: 0.9438\n",
      " expert 4: 0.9663\n",
      " expert 5: 0.9497\n",
      " expert 6: 0.9581\n",
      " expert 7: 0.9554\n",
      " expert 8: 0.9370\n",
      " expert 9: 0.9346\n",
      "\n",
      "router-train samples              : 40,000\n",
      "positive label density            : 0.0664\n",
      "epoch 1/5 | router-train BCE: 0.1618\n",
      "epoch 2/5 | router-train BCE: 0.0398\n",
      "epoch 3/5 | router-train BCE: 0.0353\n",
      "epoch 4/5 | router-train BCE: 0.0348\n",
      "epoch 5/5 | router-train BCE: 0.0340\n",
      "\n",
      "🏁  pipeline accuracy on router-val slice: 0.7709\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\t•\tRouter-training labels are now multi-hot – if several experts predict correctly, every one of those IDs is marked 1 (multi-label).\n",
    "\t•\tBCEWithLogitsLoss replaces cross-entropy so the router can “light up” multiple experts.\n",
    "\t•\tAt inference we simply take the router’s top-score expert no matter what (even if no expert was correct during training) – no more -1.\n",
    "\t•\tIf no expert happened to be correct for a router-train sample, we still keep it with all-zeros label; the BCE loss nudges logits toward 0 for that input.\n",
    "\"\"\"\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Mixture-of-Experts pipeline  (LED_a, multi-label router)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# ───────── CONFIG ───────────────────────────────────────────────────────────\n",
    "TOTAL_SAMPLES  = 1_000_00        # change to a smaller value for quick runs\n",
    "TRAIN_RATIO    = 0.80\n",
    "NUM_CLASSES    = 10\n",
    "INPUT_DIM      = 24               # 7 relevant + 17 irrelevant\n",
    "BATCH_SIZE     = 256\n",
    "EPOCHS         = 5\n",
    "LR             = 3e-3\n",
    "SEED_STREAM    = 112\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# ───────── STREAM & SPLIT ───────────────────────────────────────────────────\n",
    "stream = list(\n",
    "    synth.LEDDrift(\n",
    "        seed                = SEED_STREAM,\n",
    "        noise_percentage    = 0.10,\n",
    "        irrelevant_features = True,\n",
    "        n_drift_features    = 7\n",
    "    ).take(TOTAL_SAMPLES)\n",
    ")\n",
    "\n",
    "half           = TOTAL_SAMPLES // 2\n",
    "expert_block   = stream[:half]\n",
    "router_block   = stream[half:]\n",
    "\n",
    "exp_train_sz   = int(len(expert_block) * TRAIN_RATIO)\n",
    "rtr_train_sz   = int(len(router_block) * TRAIN_RATIO)\n",
    "\n",
    "exp_train, exp_val = expert_block[:exp_train_sz], expert_block[exp_train_sz:]\n",
    "rtr_train, rtr_val = router_block[:rtr_train_sz], router_block[rtr_train_sz:]\n",
    "\n",
    "print(\"── SPLITS ───────────────────────────────────────────\")\n",
    "print(f\" total samples         : {TOTAL_SAMPLES:,}\")\n",
    "print(f\" expert  train / val   : {len(exp_train):,} / {len(exp_val):,}\")\n",
    "print(f\" router  train / val   : {len(rtr_train):,} / {len(rtr_val):,}\")\n",
    "\n",
    "d2v = lambda d: np.fromiter(d.values(), dtype=np.float32, count=INPUT_DIM)\n",
    "\n",
    "# ───────── 1) TRAIN TEN ONE-VS-REST EXPERTS ─────────────────────────────────\n",
    "experts   = {cid: tree.HoeffdingTreeClassifier() for cid in range(NUM_CLASSES)}\n",
    "exp_val_acc = {cid: metrics.Accuracy()           for cid in range(NUM_CLASSES)}\n",
    "\n",
    "for x,y in exp_train:\n",
    "    for cid, model in experts.items():\n",
    "        model.learn_one(x, int(y == cid))\n",
    "\n",
    "for x,y in exp_val:\n",
    "    for cid, model in experts.items():\n",
    "        exp_val_acc[cid].update(int(y == cid), model.predict_one(x))\n",
    "\n",
    "print(\"\\n── EXPERT VALID ACC (first 50 %) ───────────────────\")\n",
    "for cid in range(NUM_CLASSES):\n",
    "    print(f\" expert {cid}: {exp_val_acc[cid].get():.4f}\")\n",
    "\n",
    "# ───────── 2) BUILD ROUTER-TRAIN  (multi-label targets) ────────────────────\n",
    "router_X, router_Y = [], []              # Y shape = [N, 10]\n",
    "\n",
    "for x_dict, y_true in rtr_train:\n",
    "    multi = np.zeros(NUM_CLASSES, dtype=np.float32)\n",
    "    for cid, model in experts.items():\n",
    "        if model.predict_one(x_dict) == 1 and y_true == cid:\n",
    "            multi[cid] = 1.0\n",
    "    router_X.append(d2v(x_dict))\n",
    "    router_Y.append(multi)               # keep even if all zeros\n",
    "\n",
    "router_X = np.stack(router_X)\n",
    "router_Y = np.stack(router_Y)\n",
    "\n",
    "print(f\"\\nrouter-train samples              : {len(router_Y):,}\")\n",
    "print(f\"positive label density            : {router_Y.sum()/router_Y.size:.4f}\")\n",
    "\n",
    "# ───────── 3) ROUTER MLP  (multi-label BCE loss) ───────────────────────────\n",
    "class TorchDS(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = torch.tensor(X)\n",
    "        self.Y = torch.tensor(Y)\n",
    "    def __len__(self):  return len(self.X)\n",
    "    def __getitem__(self,i): return self.X[i], self.Y[i]\n",
    "\n",
    "train_dl = DataLoader(TorchDS(router_X, router_Y),\n",
    "                      batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "class RouterMLP(nn.Module):\n",
    "    def __init__(self,in_dim=INPUT_DIM,h=128,out=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim,h), nn.SiLU(),\n",
    "            nn.Linear(h,h),       nn.SiLU(),\n",
    "            nn.Linear(h,out)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "router = RouterMLP()\n",
    "opt    = torch.optim.Adam(router.parameters(), lr=LR)\n",
    "bce    = nn.BCEWithLogitsLoss()\n",
    "\n",
    "router.train()\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    running = 0.0\n",
    "    for xb, yb in train_dl:\n",
    "        opt.zero_grad()\n",
    "        loss = bce(router(xb), yb)\n",
    "        loss.backward(); opt.step()\n",
    "        running += loss.item() * len(xb)\n",
    "    print(f\"epoch {epoch}/{EPOCHS} | router-train BCE: \"\n",
    "          f\"{running/len(train_dl.dataset):.4f}\")\n",
    "\n",
    "# ───────── 4) PIPELINE EVAL on router-val (pick top expert) ────────────────\n",
    "router.eval()\n",
    "pipe_acc = metrics.Accuracy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_dict, y_true in rtr_val:\n",
    "        logits = router(torch.tensor(d2v(x_dict))).sigmoid()\n",
    "        eid    = int(torch.argmax(logits).item())        # expert with highest prob\n",
    "        final  = eid                                     # trust that expert’s class\n",
    "        pipe_acc.update(y_true, final)\n",
    "\n",
    "print(f\"\\n🏁  pipeline accuracy on router-val slice: \"\n",
    "      f\"{pipe_acc.get():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medsam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
